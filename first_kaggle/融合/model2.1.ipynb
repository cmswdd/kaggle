{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import gc\n",
    "gc.collect()\n",
    "import os\n",
    "from six.moves import urllib\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')\n",
    "from scipy.stats import norm, skew\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Add All the Models Libraries\n",
    "\n",
    "# Scalers\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "# Models\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_log_error,mean_squared_error, r2_score,mean_absolute_error\n",
    "\n",
    "from sklearn.model_selection import train_test_split #training and testing data split\n",
    "from sklearn import metrics #accuracy measure\n",
    "from sklearn.metrics import confusion_matrix #for confusion matrix\n",
    "from scipy.stats import reciprocal, uniform\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, RepeatedKFold\n",
    "\n",
    "# Cross-validation\n",
    "from sklearn.model_selection import KFold #for K-fold cross validation\n",
    "from sklearn.model_selection import cross_val_score #score evaluation\n",
    "from sklearn.model_selection import cross_val_predict #prediction\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#Common data processors\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn import feature_selection\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.utils import check_array\n",
    "from scipy import sparse\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(123)\n",
    "gc.collect()\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "#Reduce the memory usage - Inspired by Panchajanya Banerjee\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "\n",
    "def one_hot_encoder(df, nan_as_category = True):\n",
    "    original_columns = list(df.columns)\n",
    "    categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
    "    df = pd.get_dummies(df, columns= categorical_columns, dummy_na= nan_as_category)\n",
    "    new_columns = [c for c in df.columns if c not in original_columns]\n",
    "    return df, new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to  4.04 Mb (56.2% reduction)\n",
      "Mem. usage decreased to  2.24 Mb (52.5% reduction)\n"
     ]
    }
   ],
   "source": [
    "train = reduce_mem_usage(pd.read_csv('elo-merchant-category-recommendation1/train.csv',parse_dates=[\"first_active_month\"]))\n",
    "test = reduce_mem_usage(pd.read_csv('elo-merchant-category-recommendation1/test.csv', parse_dates=[\"first_active_month\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201917, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 201917 entries, 0 to 201916\n",
      "Data columns (total 6 columns):\n",
      "first_active_month    201917 non-null datetime64[ns]\n",
      "card_id               201917 non-null object\n",
      "feature_1             201917 non-null int8\n",
      "feature_2             201917 non-null int8\n",
      "feature_3             201917 non-null int8\n",
      "target                201917 non-null float16\n",
      "dtypes: datetime64[ns](1), float16(1), int8(3), object(1)\n",
      "memory usage: 4.0+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now extract the month, year, day, weekday\n",
    "train[\"month\"] = train[\"first_active_month\"].dt.month\n",
    "train[\"year\"] = train[\"first_active_month\"].dt.year\n",
    "train['week'] = train[\"first_active_month\"].dt.weekofyear\n",
    "train['dayofweek'] = train['first_active_month'].dt.dayofweek\n",
    "train['days'] = (datetime.date(2018, 2, 1) - train['first_active_month'].dt.date).dt.days\n",
    "train['quarter'] = train['first_active_month'].dt.quarter\n",
    "train['is_month_start'] = train['first_active_month'].dt.is_month_start\n",
    "\n",
    "#Interaction Variables\n",
    "train['days_feature1'] = train['days'] * train['feature_1']\n",
    "train['days_feature2'] = train['days'] * train['feature_2']\n",
    "train['days_feature3'] = train['days'] * train['feature_3']\n",
    "\n",
    "test[\"month\"] = test[\"first_active_month\"].dt.month\n",
    "test[\"year\"] = test[\"first_active_month\"].dt.year\n",
    "test['week'] = test[\"first_active_month\"].dt.weekofyear\n",
    "test['dayofweek'] = test['first_active_month'].dt.dayofweek\n",
    "test['days'] = (datetime.date(2018, 2, 1) - test['first_active_month'].dt.date).dt.days\n",
    "test['quarter'] = test['first_active_month'].dt.quarter\n",
    "test['is_month_start'] = test['first_active_month'].dt.is_month_start\n",
    "\n",
    "#Interaction Variables\n",
    "test['days_feature1'] = test['days'] * train['feature_1']\n",
    "test['days_feature2'] = test['days'] * train['feature_2']\n",
    "test['days_feature3'] = test['days'] * train['feature_3']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_transaction_hist(trans, prefix):  \n",
    "        \n",
    "    agg_func = {\n",
    "        'purchase_date' : ['max','min'],\n",
    "        'month_diff' : ['mean', 'min', 'max', 'var'],\n",
    "        'weekend' : ['sum', 'mean'],\n",
    "        'authorized_flag': ['sum', 'mean'],\n",
    "        'category_1': ['sum','mean', 'max','min'],\n",
    "        'purchase_amount': ['sum', 'mean', 'max', 'min', 'std'],\n",
    "        'installments': ['sum', 'mean', 'max', 'min', 'std'],  \n",
    "        'month_lag': ['max','min','mean','var'],\n",
    "        'card_id' : ['size'],\n",
    "        'month': ['nunique'],\n",
    "        'hour': ['nunique'],\n",
    "        'weekofyear': ['nunique'],\n",
    "        'dayofweek': ['nunique'],\n",
    "        'year': ['nunique'],\n",
    "        'subsector_id': ['nunique'],\n",
    "        'merchant_category_id' : ['nunique']\n",
    "    }\n",
    "    \n",
    "    agg_trans = trans.groupby(['card_id']).agg(agg_func)\n",
    "    agg_trans.columns = [prefix + '_'.join(col).strip() \n",
    "                           for col in agg_trans.columns.values]\n",
    "    agg_trans.reset_index(inplace=True)\n",
    "    \n",
    "    df = (trans.groupby('card_id')\n",
    "          .size()\n",
    "          .reset_index(name='{}transactions_count'.format(prefix)))\n",
    "    \n",
    "    agg_trans = pd.merge(df, agg_trans, on='card_id', how='left')\n",
    "    \n",
    "    return agg_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 1749.11 Mb (43.7% reduction)\n"
     ]
    }
   ],
   "source": [
    "transactions = reduce_mem_usage(pd.read_csv('../input/historical_transactions.csv'))\n",
    "transactions['authorized_flag'] = transactions['authorized_flag'].map({'Y': 1, 'N': 0})\n",
    "transactions['category_1'] = transactions['category_1'].map({'Y': 1, 'N': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Feature Engineering - Adding new features inspired by Chau's first kernel\n",
    "transactions['purchase_date'] = pd.to_datetime(transactions['purchase_date'])\n",
    "transactions['year'] = transactions['purchase_date'].dt.year\n",
    "transactions['weekofyear'] = transactions['purchase_date'].dt.weekofyear\n",
    "transactions['month'] = transactions['purchase_date'].dt.month\n",
    "transactions['dayofweek'] = transactions['purchase_date'].dt.dayofweek\n",
    "transactions['weekend'] = (transactions.purchase_date.dt.weekday >=5).astype(int)\n",
    "transactions['hour'] = transactions['purchase_date'].dt.hour \n",
    "transactions['quarter'] = transactions['purchase_date'].dt.quarter\n",
    "transactions['is_month_start'] = transactions['purchase_date'].dt.is_month_start\n",
    "transactions['month_diff'] = ((datetime.datetime.today() - transactions['purchase_date']).dt.days)//30\n",
    "transactions['month_diff'] += transactions['month_lag']\n",
    "\n",
    "#impute missing values - This is now excluded.\n",
    "transactions['category_2'] = transactions['category_2'].fillna(1.0,inplace=True)\n",
    "transactions['category_3'] = transactions['category_3'].fillna('A',inplace=True)\n",
    "transactions['merchant_id'] = transactions['merchant_id'].fillna('M_ID_00a6ca8a8a',inplace=True)\n",
    "\n",
    "transactions['category_3'] = transactions['category_3'].map({'A':0, 'B':1, 'C':2})\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_func = {\n",
    "        'mean': ['mean'],\n",
    "    }\n",
    "for col in ['category_2','category_3']:\n",
    "    transactions[col+'_mean'] = transactions['purchase_amount'].groupby(transactions[col]).agg('mean')\n",
    "    transactions[col+'_max'] = transactions['purchase_amount'].groupby(transactions[col]).agg('max')\n",
    "    transactions[col+'_min'] = transactions['purchase_amount'].groupby(transactions[col]).agg('min')\n",
    "    transactions[col+'_sum'] = transactions['purchase_amount'].groupby(transactions[col]).agg('sum')\n",
    "    agg_func[col+'_mean'] = ['mean']\n",
    "    \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_trans = aggregate_transaction_hist(transactions, prefix='hist_')\n",
    "del transactions\n",
    "gc.collect()\n",
    "train = pd.merge(train, merge_trans, on='card_id',how='left')\n",
    "test = pd.merge(test, merge_trans, on='card_id',how='left')\n",
    "del merge_trans\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Feature Engineering - Adding new features inspired by Chau's first kernel\n",
    "train['hist_purchase_date_max'] = pd.to_datetime(train['hist_purchase_date_max'])\n",
    "train['hist_purchase_date_min'] = pd.to_datetime(train['hist_purchase_date_min'])\n",
    "train['hist_purchase_date_diff'] = (train['hist_purchase_date_max'] - train['hist_purchase_date_min']).dt.days\n",
    "train['hist_purchase_date_average'] = train['hist_purchase_date_diff']/train['hist_card_id_size']\n",
    "train['hist_purchase_date_uptonow'] = (datetime.datetime.today() - train['hist_purchase_date_max']).dt.days\n",
    "train['hist_purchase_date_uptomin'] = (datetime.datetime.today() - train['hist_purchase_date_min']).dt.days\n",
    "train['hist_first_buy'] = (train['hist_purchase_date_min'] - train['first_active_month']).dt.days\n",
    "\n",
    "for feature in ['hist_purchase_date_max','hist_purchase_date_min']:\n",
    "    train[feature] = train[feature].astype(np.int64) * 1e-9\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Feature Engineering - Adding new features inspired by Chau's first kernel\n",
    "test['hist_purchase_date_max'] = pd.to_datetime(test['hist_purchase_date_max']) \n",
    "test['hist_purchase_date_min'] = pd.to_datetime(test['hist_purchase_date_min'])\n",
    "test['hist_purchase_date_diff'] = (test['hist_purchase_date_max'] - test['hist_purchase_date_min']).dt.days\n",
    "test['hist_purchase_date_average'] = test['hist_purchase_date_diff']/test['hist_card_id_size']\n",
    "test['hist_purchase_date_uptonow'] = (datetime.datetime.today() - test['hist_purchase_date_max']).dt.days\n",
    "test['hist_purchase_date_uptomin'] = (datetime.datetime.today() - test['hist_purchase_date_min']).dt.days\n",
    "\n",
    "test['hist_first_buy'] = (test['hist_purchase_date_min'] - test['first_active_month']).dt.days\n",
    "\n",
    "for feature in ['hist_purchase_date_max','hist_purchase_date_min']:\n",
    "    test[feature] = test[feature].astype(np.int64) * 1e-9\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_active_month</th>\n",
       "      <th>card_id</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>target</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>week</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>...</th>\n",
       "      <th>hist_weekofyear_nunique</th>\n",
       "      <th>hist_dayofweek_nunique</th>\n",
       "      <th>hist_year_nunique</th>\n",
       "      <th>hist_subsector_id_nunique</th>\n",
       "      <th>hist_merchant_category_id_nunique</th>\n",
       "      <th>hist_purchase_date_diff</th>\n",
       "      <th>hist_purchase_date_average</th>\n",
       "      <th>hist_purchase_date_uptonow</th>\n",
       "      <th>hist_purchase_date_uptomin</th>\n",
       "      <th>hist_first_buy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>C_ID_92a2005557</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.820312</td>\n",
       "      <td>6</td>\n",
       "      <td>2017</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>41</td>\n",
       "      <td>242</td>\n",
       "      <td>0.930769</td>\n",
       "      <td>342</td>\n",
       "      <td>584</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>C_ID_3d0044924f</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.392822</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>57</td>\n",
       "      <td>390</td>\n",
       "      <td>1.114286</td>\n",
       "      <td>366</td>\n",
       "      <td>756</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>C_ID_d639edf6cd</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.687988</td>\n",
       "      <td>8</td>\n",
       "      <td>2016</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>412</td>\n",
       "      <td>9.581395</td>\n",
       "      <td>339</td>\n",
       "      <td>752</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>C_ID_186d6a6901</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.142456</td>\n",
       "      <td>9</td>\n",
       "      <td>2017</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>25</td>\n",
       "      <td>154</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>339</td>\n",
       "      <td>493</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-11-01</td>\n",
       "      <td>C_ID_cdbd2c0db2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.159790</td>\n",
       "      <td>11</td>\n",
       "      <td>2017</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>26</td>\n",
       "      <td>108</td>\n",
       "      <td>0.812030</td>\n",
       "      <td>338</td>\n",
       "      <td>447</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>C_ID_0894217f2f</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.871582</td>\n",
       "      <td>9</td>\n",
       "      <td>2016</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>199</td>\n",
       "      <td>6.030303</td>\n",
       "      <td>552</td>\n",
       "      <td>752</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016-12-01</td>\n",
       "      <td>C_ID_7e63323c00</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.230103</td>\n",
       "      <td>12</td>\n",
       "      <td>2016</td>\n",
       "      <td>48</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>48</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>414</td>\n",
       "      <td>1.592308</td>\n",
       "      <td>343</td>\n",
       "      <td>758</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>C_ID_dfa21fc124</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.136719</td>\n",
       "      <td>9</td>\n",
       "      <td>2017</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>83</td>\n",
       "      <td>3.772727</td>\n",
       "      <td>407</td>\n",
       "      <td>491</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2017-08-01</td>\n",
       "      <td>C_ID_fe0fdac8ea</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.065430</td>\n",
       "      <td>8</td>\n",
       "      <td>2017</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>112</td>\n",
       "      <td>7.466667</td>\n",
       "      <td>420</td>\n",
       "      <td>532</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>C_ID_bf62c0b49d</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.300049</td>\n",
       "      <td>8</td>\n",
       "      <td>2016</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>33</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>29</td>\n",
       "      <td>415</td>\n",
       "      <td>3.672566</td>\n",
       "      <td>338</td>\n",
       "      <td>753</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  first_active_month          card_id  feature_1  feature_2  feature_3  \\\n",
       "0         2017-06-01  C_ID_92a2005557          5          2          1   \n",
       "1         2017-01-01  C_ID_3d0044924f          4          1          0   \n",
       "2         2016-08-01  C_ID_d639edf6cd          2          2          0   \n",
       "3         2017-09-01  C_ID_186d6a6901          4          3          0   \n",
       "4         2017-11-01  C_ID_cdbd2c0db2          1          3          0   \n",
       "5         2016-09-01  C_ID_0894217f2f          4          2          0   \n",
       "6         2016-12-01  C_ID_7e63323c00          3          2          1   \n",
       "7         2017-09-01  C_ID_dfa21fc124          3          2          1   \n",
       "8         2017-08-01  C_ID_fe0fdac8ea          2          1          0   \n",
       "9         2016-08-01  C_ID_bf62c0b49d          2          2          0   \n",
       "\n",
       "     target  month  year  week  dayofweek       ...        \\\n",
       "0 -0.820312      6  2017    22          3       ...         \n",
       "1  0.392822      1  2017    52          6       ...         \n",
       "2  0.687988      8  2016    31          0       ...         \n",
       "3  0.142456      9  2017    35          4       ...         \n",
       "4 -0.159790     11  2017    44          2       ...         \n",
       "5  0.871582      9  2016    35          3       ...         \n",
       "6  0.230103     12  2016    48          3       ...         \n",
       "7  2.136719      9  2017    35          4       ...         \n",
       "8 -0.065430      8  2017    31          1       ...         \n",
       "9  0.300049      8  2016    31          0       ...         \n",
       "\n",
       "   hist_weekofyear_nunique  hist_dayofweek_nunique  hist_year_nunique  \\\n",
       "0                       35                       7                  2   \n",
       "1                       50                       7                  2   \n",
       "2                       22                       7                  2   \n",
       "3                       20                       7                  2   \n",
       "4                       17                       7                  2   \n",
       "5                       16                       6                  1   \n",
       "6                       48                       7                  2   \n",
       "7                        8                       7                  1   \n",
       "8                        6                       5                  1   \n",
       "9                       33                       7                  2   \n",
       "\n",
       "   hist_subsector_id_nunique  hist_merchant_category_id_nunique  \\\n",
       "0                         21                                 41   \n",
       "1                         24                                 57   \n",
       "2                          7                                  8   \n",
       "3                         13                                 25   \n",
       "4                         17                                 26   \n",
       "5                          8                                 14   \n",
       "6                         12                                 23   \n",
       "7                          6                                  7   \n",
       "8                          4                                  4   \n",
       "9                         13                                 29   \n",
       "\n",
       "   hist_purchase_date_diff  hist_purchase_date_average  \\\n",
       "0                      242                    0.930769   \n",
       "1                      390                    1.114286   \n",
       "2                      412                    9.581395   \n",
       "3                      154                    2.000000   \n",
       "4                      108                    0.812030   \n",
       "5                      199                    6.030303   \n",
       "6                      414                    1.592308   \n",
       "7                       83                    3.772727   \n",
       "8                      112                    7.466667   \n",
       "9                      415                    3.672566   \n",
       "\n",
       "   hist_purchase_date_uptonow  hist_purchase_date_uptomin  hist_first_buy  \n",
       "0                         342                         584              26  \n",
       "1                         366                         756               5  \n",
       "2                         339                         752             163  \n",
       "3                         339                         493              25  \n",
       "4                         338                         447              11  \n",
       "5                         552                         752             131  \n",
       "6                         343                         758              35  \n",
       "7                         407                         491              27  \n",
       "8                         420                         532              17  \n",
       "9                         338                         753             161  \n",
       "\n",
       "[10 rows x 58 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking Reference from Other Kernels\n",
    "def aggregate_transaction_new(trans, prefix):  \n",
    "        \n",
    "    agg_func = {\n",
    "        'purchase_date' : ['max','min'],\n",
    "        'month_diff' : ['mean', 'min', 'max', 'var'],\n",
    "        'weekend' : ['sum', 'mean'],\n",
    "        'authorized_flag': ['sum', 'mean'],\n",
    "        'category_1': ['sum','mean', 'max','min'],\n",
    "        'purchase_amount': ['sum', 'mean', 'max', 'min', 'std'],\n",
    "        'installments': ['sum', 'mean', 'max', 'min', 'std'],  \n",
    "        'month_lag': ['max','min','mean','var'],\n",
    "        'card_id' : ['size'],\n",
    "        'month': ['nunique'],\n",
    "        'hour': ['nunique'],\n",
    "        'weekofyear': ['nunique'],\n",
    "        'dayofweek': ['nunique'],\n",
    "        'year': ['nunique'],\n",
    "        'subsector_id': ['nunique'],\n",
    "        'merchant_category_id' : ['nunique']\n",
    "    }\n",
    "    \n",
    "    agg_trans = trans.groupby(['card_id']).agg(agg_func)\n",
    "    agg_trans.columns = [prefix + '_'.join(col).strip() \n",
    "                           for col in agg_trans.columns.values]\n",
    "    agg_trans.reset_index(inplace=True)\n",
    "    \n",
    "    df = (trans.groupby('card_id')\n",
    "          .size()\n",
    "          .reset_index(name='{}transactions_count'.format(prefix)))\n",
    "    \n",
    "    agg_trans = pd.merge(df, agg_trans, on='card_id', how='left')\n",
    "    \n",
    "    return agg_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 114.20 Mb (45.5% reduction)\n"
     ]
    }
   ],
   "source": [
    "# Now extract the data from the new transactions\n",
    "new_transactions = reduce_mem_usage(pd.read_csv('../input/new_merchant_transactions.csv'))\n",
    "new_transactions['authorized_flag'] = new_transactions['authorized_flag'].map({'Y': 1, 'N': 0})\n",
    "new_transactions['category_1'] = new_transactions['category_1'].map({'Y': 1, 'N': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Feature Engineering - Adding new features inspired by Chau's first kernel\n",
    "new_transactions['purchase_date'] = pd.to_datetime(new_transactions['purchase_date'])\n",
    "new_transactions['year'] = new_transactions['purchase_date'].dt.year\n",
    "new_transactions['weekofyear'] = new_transactions['purchase_date'].dt.weekofyear\n",
    "new_transactions['month'] = new_transactions['purchase_date'].dt.month\n",
    "new_transactions['dayofweek'] = new_transactions['purchase_date'].dt.dayofweek\n",
    "new_transactions['weekend'] = (new_transactions.purchase_date.dt.weekday >=5).astype(int)\n",
    "new_transactions['hour'] = new_transactions['purchase_date'].dt.hour \n",
    "new_transactions['quarter'] = new_transactions['purchase_date'].dt.quarter\n",
    "new_transactions['is_month_start'] = new_transactions['purchase_date'].dt.is_month_start\n",
    "new_transactions['month_diff'] = ((datetime.datetime.today() - new_transactions['purchase_date']).dt.days)//30\n",
    "new_transactions['month_diff'] += new_transactions['month_lag']\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "#impute missing values\n",
    "new_transactions['category_2'] = new_transactions['category_2'].fillna(1.0,inplace=False)\n",
    "new_transactions['category_3'] = new_transactions['category_3'].fillna('A',inplace=False)\n",
    "new_transactions['merchant_id'] = new_transactions['merchant_id'].fillna('M_ID_00a6ca8a8a',inplace=False)\n",
    "\n",
    "new_transactions['category_3'] = new_transactions['category_3'].map({'A':0, 'B':1, 'C':2}) \n",
    "\n",
    "aggs = {\n",
    "        'mean': ['mean'],\n",
    "    }\n",
    "\n",
    "for col in ['category_2','category_3']:\n",
    "    new_transactions[col+'_mean'] = new_transactions['purchase_amount'].groupby(new_transactions[col]).agg('mean')\n",
    "    new_transactions[col+'_max'] = new_transactions['purchase_amount'].groupby(new_transactions[col]).agg('max')\n",
    "    new_transactions[col+'_min'] = new_transactions['purchase_amount'].groupby(new_transactions[col]).agg('min')\n",
    "    new_transactions[col+'_var'] = new_transactions['purchase_amount'].groupby(new_transactions[col]).agg('var')\n",
    "    aggs[col+'_mean'] = ['mean']\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_new = aggregate_transaction_new(new_transactions, prefix='new_')\n",
    "del new_transactions\n",
    "gc.collect()\n",
    "\n",
    "train = pd.merge(train, merge_new, on='card_id',how='left')\n",
    "test = pd.merge(test, merge_new, on='card_id',how='left')\n",
    "del merge_new\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Feature Engineering - Adding new features inspired by Chau's first kernel\n",
    "train['new_purchase_date_max'] = pd.to_datetime(train['new_purchase_date_max'])\n",
    "train['new_purchase_date_min'] = pd.to_datetime(train['new_purchase_date_min'])\n",
    "train['new_purchase_date_diff'] = (train['new_purchase_date_max'] - train['new_purchase_date_min']).dt.days\n",
    "train['new_purchase_date_average'] = train['new_purchase_date_diff']/train['new_card_id_size']\n",
    "train['new_purchase_date_uptonow'] = (datetime.datetime.today() - train['new_purchase_date_max']).dt.days\n",
    "train['new_purchase_date_uptomin'] = (datetime.datetime.today() - train['new_purchase_date_min']).dt.days\n",
    "train['new_first_buy'] = (train['new_purchase_date_min'] - train['first_active_month']).dt.days\n",
    "for feature in ['new_purchase_date_max','new_purchase_date_min']:\n",
    "    train[feature] = train[feature].astype(np.int64) * 1e-9\n",
    "\n",
    "#Feature Engineering - Adding new features inspired by Chau's first kernel\n",
    "test['new_purchase_date_max'] = pd.to_datetime(test['new_purchase_date_max'])\n",
    "test['new_purchase_date_min'] = pd.to_datetime(test['new_purchase_date_min'])\n",
    "test['new_purchase_date_diff'] = (test['new_purchase_date_max'] - test['new_purchase_date_min']).dt.days\n",
    "test['new_purchase_date_average'] = test['new_purchase_date_diff']/test['new_card_id_size']\n",
    "test['new_purchase_date_uptonow'] = (datetime.datetime.today() - test['new_purchase_date_max']).dt.days\n",
    "test['new_purchase_date_uptomin'] = (datetime.datetime.today() - test['new_purchase_date_min']).dt.days\n",
    "test['new_first_buy'] = (test['new_purchase_date_min'] - test['first_active_month']).dt.days\n",
    "for feature in ['new_purchase_date_max','new_purchase_date_min']:\n",
    "    test[feature] = test[feature].astype(np.int64) * 1e-9\n",
    "    \n",
    "#added new feature - Interactive\n",
    "train['card_id_total'] = train['new_card_id_size'] + train['hist_card_id_size']\n",
    "train['purchase_amount_total'] = train['new_purchase_amount_sum'] + train['hist_purchase_amount_sum']\n",
    "\n",
    "test['card_id_total'] = test['new_card_id_size'] + test['hist_card_id_size']\n",
    "test['purchase_amount_total'] = test['new_purchase_amount_sum'] + test['hist_purchase_amount_sum']\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Observations</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>new_purchase_amount_std</th>\n",
       "      <td>48718</td>\n",
       "      <td>24.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_installments_std</th>\n",
       "      <td>48718</td>\n",
       "      <td>24.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_month_diff_var</th>\n",
       "      <td>48718</td>\n",
       "      <td>24.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_month_lag_var</th>\n",
       "      <td>48718</td>\n",
       "      <td>24.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_category_1_mean</th>\n",
       "      <td>21931</td>\n",
       "      <td>10.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_purchase_amount_min</th>\n",
       "      <td>21931</td>\n",
       "      <td>10.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_purchase_amount_max</th>\n",
       "      <td>21931</td>\n",
       "      <td>10.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_purchase_amount_mean</th>\n",
       "      <td>21931</td>\n",
       "      <td>10.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_purchase_amount_sum</th>\n",
       "      <td>21931</td>\n",
       "      <td>10.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_category_1_min</th>\n",
       "      <td>21931</td>\n",
       "      <td>10.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_category_1_max</th>\n",
       "      <td>21931</td>\n",
       "      <td>10.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>purchase_amount_total</th>\n",
       "      <td>21931</td>\n",
       "      <td>10.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_installments_sum</th>\n",
       "      <td>21931</td>\n",
       "      <td>10.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_authorized_flag_mean</th>\n",
       "      <td>21931</td>\n",
       "      <td>10.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_authorized_flag_sum</th>\n",
       "      <td>21931</td>\n",
       "      <td>10.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_weekend_sum</th>\n",
       "      <td>21931</td>\n",
       "      <td>10.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_month_diff_max</th>\n",
       "      <td>21931</td>\n",
       "      <td>10.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_month_diff_min</th>\n",
       "      <td>21931</td>\n",
       "      <td>10.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_month_diff_mean</th>\n",
       "      <td>21931</td>\n",
       "      <td>10.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_transactions_count</th>\n",
       "      <td>21931</td>\n",
       "      <td>10.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>card_id_total</th>\n",
       "      <td>21931</td>\n",
       "      <td>10.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_category_1_sum</th>\n",
       "      <td>21931</td>\n",
       "      <td>10.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_weekend_mean</th>\n",
       "      <td>21931</td>\n",
       "      <td>10.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_installments_mean</th>\n",
       "      <td>21931</td>\n",
       "      <td>10.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_dayofweek_nunique</th>\n",
       "      <td>21931</td>\n",
       "      <td>10.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_first_buy</th>\n",
       "      <td>21931</td>\n",
       "      <td>10.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_installments_max</th>\n",
       "      <td>21931</td>\n",
       "      <td>10.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_purchase_date_uptomin</th>\n",
       "      <td>21931</td>\n",
       "      <td>10.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_purchase_date_uptonow</th>\n",
       "      <td>21931</td>\n",
       "      <td>10.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_purchase_date_diff</th>\n",
       "      <td>21931</td>\n",
       "      <td>10.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hist_category_1_min</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hist_purchase_amount_sum</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_purchase_date_min</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_purchase_date_max</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hist_first_buy</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hist_purchase_date_uptomin</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hist_purchase_date_uptonow</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hist_purchase_date_average</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hist_purchase_date_diff</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hist_merchant_category_id_nunique</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hist_subsector_id_nunique</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hist_dayofweek_nunique</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hist_weekofyear_nunique</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hist_hour_nunique</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hist_month_nunique</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hist_card_id_size</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hist_month_lag_var</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hist_month_lag_mean</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hist_month_lag_min</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hist_month_lag_max</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hist_installments_std</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hist_installments_min</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hist_installments_max</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hist_installments_mean</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hist_installments_sum</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hist_purchase_amount_std</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hist_purchase_amount_min</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hist_purchase_amount_max</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hist_purchase_amount_mean</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_active_month</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Number of Observations  Percent\n",
       "new_purchase_amount_std                             48718    24.13\n",
       "new_installments_std                                48718    24.13\n",
       "new_month_diff_var                                  48718    24.13\n",
       "new_month_lag_var                                   48718    24.13\n",
       "new_category_1_mean                                 21931    10.86\n",
       "new_purchase_amount_min                             21931    10.86\n",
       "new_purchase_amount_max                             21931    10.86\n",
       "new_purchase_amount_mean                            21931    10.86\n",
       "new_purchase_amount_sum                             21931    10.86\n",
       "new_category_1_min                                  21931    10.86\n",
       "new_category_1_max                                  21931    10.86\n",
       "purchase_amount_total                               21931    10.86\n",
       "new_installments_sum                                21931    10.86\n",
       "new_authorized_flag_mean                            21931    10.86\n",
       "new_authorized_flag_sum                             21931    10.86\n",
       "new_weekend_sum                                     21931    10.86\n",
       "new_month_diff_max                                  21931    10.86\n",
       "new_month_diff_min                                  21931    10.86\n",
       "new_month_diff_mean                                 21931    10.86\n",
       "new_transactions_count                              21931    10.86\n",
       "card_id_total                                       21931    10.86\n",
       "new_category_1_sum                                  21931    10.86\n",
       "new_weekend_mean                                    21931    10.86\n",
       "new_installments_mean                               21931    10.86\n",
       "new_dayofweek_nunique                               21931    10.86\n",
       "new_first_buy                                       21931    10.86\n",
       "new_installments_max                                21931    10.86\n",
       "new_purchase_date_uptomin                           21931    10.86\n",
       "new_purchase_date_uptonow                           21931    10.86\n",
       "new_purchase_date_diff                              21931    10.86\n",
       "...                                                   ...      ...\n",
       "hist_category_1_min                                     0     0.00\n",
       "hist_purchase_amount_sum                                0     0.00\n",
       "new_purchase_date_min                                   0     0.00\n",
       "new_purchase_date_max                                   0     0.00\n",
       "hist_first_buy                                          0     0.00\n",
       "hist_purchase_date_uptomin                              0     0.00\n",
       "hist_purchase_date_uptonow                              0     0.00\n",
       "hist_purchase_date_average                              0     0.00\n",
       "hist_purchase_date_diff                                 0     0.00\n",
       "hist_merchant_category_id_nunique                       0     0.00\n",
       "hist_subsector_id_nunique                               0     0.00\n",
       "hist_dayofweek_nunique                                  0     0.00\n",
       "hist_weekofyear_nunique                                 0     0.00\n",
       "hist_hour_nunique                                       0     0.00\n",
       "hist_month_nunique                                      0     0.00\n",
       "hist_card_id_size                                       0     0.00\n",
       "hist_month_lag_var                                      0     0.00\n",
       "hist_month_lag_mean                                     0     0.00\n",
       "hist_month_lag_min                                      0     0.00\n",
       "hist_month_lag_max                                      0     0.00\n",
       "hist_installments_std                                   0     0.00\n",
       "hist_installments_min                                   0     0.00\n",
       "hist_installments_max                                   0     0.00\n",
       "hist_installments_mean                                  0     0.00\n",
       "hist_installments_sum                                   0     0.00\n",
       "hist_purchase_amount_std                                0     0.00\n",
       "hist_purchase_amount_min                                0     0.00\n",
       "hist_purchase_amount_max                                0     0.00\n",
       "hist_purchase_amount_mean                               0     0.00\n",
       "first_active_month                                      0     0.00\n",
       "\n",
       "[102 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for Missing Values after Concatination\n",
    "\n",
    "obs = train.isnull().sum().sort_values(ascending = False)\n",
    "percent = round(train.isnull().sum().sort_values(ascending = False)/len(train)*100, 2)\n",
    "pd.concat([obs, percent], axis = 1,keys= ['Number of Observations', 'Percent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_active_month</th>\n",
       "      <th>card_id</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>target</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>week</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>...</th>\n",
       "      <th>new_year_nunique</th>\n",
       "      <th>new_subsector_id_nunique</th>\n",
       "      <th>new_merchant_category_id_nunique</th>\n",
       "      <th>new_purchase_date_diff</th>\n",
       "      <th>new_purchase_date_average</th>\n",
       "      <th>new_purchase_date_uptonow</th>\n",
       "      <th>new_purchase_date_uptomin</th>\n",
       "      <th>new_first_buy</th>\n",
       "      <th>card_id_total</th>\n",
       "      <th>purchase_amount_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>C_ID_92a2005557</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.820312</td>\n",
       "      <td>6</td>\n",
       "      <td>2017</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2.347826</td>\n",
       "      <td>279.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>283.0</td>\n",
       "      <td>-179.210922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>C_ID_3d0044924f</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.392822</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>309.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>396.0</td>\n",
       "      <td>356.0</td>\n",
       "      <td>-214.361801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>C_ID_d639edf6cd</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.687988</td>\n",
       "      <td>8</td>\n",
       "      <td>2016</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>279.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>635.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>-29.867586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>C_ID_186d6a6901</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.142456</td>\n",
       "      <td>9</td>\n",
       "      <td>2017</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>5.857143</td>\n",
       "      <td>290.0</td>\n",
       "      <td>332.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>-54.147614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-11-01</td>\n",
       "      <td>C_ID_cdbd2c0db2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.159790</td>\n",
       "      <td>11</td>\n",
       "      <td>2017</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1.583333</td>\n",
       "      <td>279.0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>-68.609528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>C_ID_0894217f2f</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.871582</td>\n",
       "      <td>9</td>\n",
       "      <td>2016</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>7.750000</td>\n",
       "      <td>504.0</td>\n",
       "      <td>536.0</td>\n",
       "      <td>348.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>-15.175645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016-12-01</td>\n",
       "      <td>C_ID_7e63323c00</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.230103</td>\n",
       "      <td>12</td>\n",
       "      <td>2016</td>\n",
       "      <td>48</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>301.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>460.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>-189.023148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>C_ID_dfa21fc124</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.136719</td>\n",
       "      <td>9</td>\n",
       "      <td>2017</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>348.0</td>\n",
       "      <td>361.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-15.663501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2017-08-01</td>\n",
       "      <td>C_ID_fe0fdac8ea</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.065430</td>\n",
       "      <td>8</td>\n",
       "      <td>2017</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>318.0</td>\n",
       "      <td>321.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-9.972046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>C_ID_bf62c0b49d</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.300049</td>\n",
       "      <td>8</td>\n",
       "      <td>2016</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>300.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>608.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>-79.137749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  first_active_month          card_id  feature_1  feature_2  feature_3  \\\n",
       "0         2017-06-01  C_ID_92a2005557          5          2          1   \n",
       "1         2017-01-01  C_ID_3d0044924f          4          1          0   \n",
       "2         2016-08-01  C_ID_d639edf6cd          2          2          0   \n",
       "3         2017-09-01  C_ID_186d6a6901          4          3          0   \n",
       "4         2017-11-01  C_ID_cdbd2c0db2          1          3          0   \n",
       "5         2016-09-01  C_ID_0894217f2f          4          2          0   \n",
       "6         2016-12-01  C_ID_7e63323c00          3          2          1   \n",
       "7         2017-09-01  C_ID_dfa21fc124          3          2          1   \n",
       "8         2017-08-01  C_ID_fe0fdac8ea          2          1          0   \n",
       "9         2016-08-01  C_ID_bf62c0b49d          2          2          0   \n",
       "\n",
       "     target  month  year  week  dayofweek          ...            \\\n",
       "0 -0.820312      6  2017    22          3          ...             \n",
       "1  0.392822      1  2017    52          6          ...             \n",
       "2  0.687988      8  2016    31          0          ...             \n",
       "3  0.142456      9  2017    35          4          ...             \n",
       "4 -0.159790     11  2017    44          2          ...             \n",
       "5  0.871582      9  2016    35          3          ...             \n",
       "6  0.230103     12  2016    48          3          ...             \n",
       "7  2.136719      9  2017    35          4          ...             \n",
       "8 -0.065430      8  2017    31          1          ...             \n",
       "9  0.300049      8  2016    31          0          ...             \n",
       "\n",
       "   new_year_nunique  new_subsector_id_nunique  \\\n",
       "0               1.0                      10.0   \n",
       "1               1.0                       4.0   \n",
       "2               1.0                       1.0   \n",
       "3               1.0                       5.0   \n",
       "4               1.0                      10.0   \n",
       "5               1.0                       4.0   \n",
       "6               1.0                       4.0   \n",
       "7               1.0                       3.0   \n",
       "8               1.0                       2.0   \n",
       "9               1.0                       2.0   \n",
       "\n",
       "   new_merchant_category_id_nunique  new_purchase_date_diff  \\\n",
       "0                              14.0                    54.0   \n",
       "1                               5.0                    56.0   \n",
       "2                               1.0                     0.0   \n",
       "3                               6.0                    41.0   \n",
       "4                              17.0                    57.0   \n",
       "5                               4.0                    31.0   \n",
       "6                               5.0                    31.0   \n",
       "7                               3.0                    12.0   \n",
       "8                               2.0                     3.0   \n",
       "9                               3.0                     7.0   \n",
       "\n",
       "   new_purchase_date_average  new_purchase_date_uptonow  \\\n",
       "0                   2.347826                      279.0   \n",
       "1                   9.333333                      309.0   \n",
       "2                   0.000000                      279.0   \n",
       "3                   5.857143                      290.0   \n",
       "4                   1.583333                      279.0   \n",
       "5                   7.750000                      504.0   \n",
       "6                   6.200000                      301.0   \n",
       "7                   4.000000                      348.0   \n",
       "8                   1.500000                      318.0   \n",
       "9                   2.333333                      300.0   \n",
       "\n",
       "   new_purchase_date_uptomin  new_first_buy  card_id_total  \\\n",
       "0                      333.0          277.0          283.0   \n",
       "1                      365.0          396.0          356.0   \n",
       "2                      279.0          635.0           44.0   \n",
       "3                      332.0          187.0           84.0   \n",
       "4                      337.0          121.0          169.0   \n",
       "5                      536.0          348.0           37.0   \n",
       "6                      333.0          460.0          265.0   \n",
       "7                      361.0          158.0           25.0   \n",
       "8                      321.0          228.0           17.0   \n",
       "9                      307.0          608.0          116.0   \n",
       "\n",
       "   purchase_amount_total  \n",
       "0            -179.210922  \n",
       "1            -214.361801  \n",
       "2             -29.867586  \n",
       "3             -54.147614  \n",
       "4             -68.609528  \n",
       "5             -15.175645  \n",
       "6            -189.023148  \n",
       "7             -15.663501  \n",
       "8              -9.972046  \n",
       "9             -79.137749  \n",
       "\n",
       "[10 rows x 102 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fill Na with 0\n",
    "train = train.fillna(0,inplace=False)\n",
    "# Now check the shape of Train and Test Data\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(['card_id', 'first_active_month'], axis = 1)\n",
    "test = test.drop(['card_id', 'first_active_month'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill Na with 0\n",
    "train = train.fillna(0,inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    199710\n",
       "1      2207\n",
       "Name: outliers, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the Outliers if any \n",
    "train['outliers'] = 0\n",
    "train.loc[train['target'] < -30, 'outliers'] = 1\n",
    "train['outliers'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for features in ['feature_1','feature_2','feature_3']:\n",
    "    order_label = train.groupby([features])['outliers'].mean()\n",
    "    train[features] = train[features].map(order_label)\n",
    "    test[features] =  test[features].map(order_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the X and Y\n",
    "df_train_columns = [c for c in train.columns if c not in ['target','outliers']] \n",
    "cat_features = [c for c in df_train_columns if 'feature_' in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train['target']\n",
    "del train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#特征处理完毕"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[909]\ttraining's rmse: 3.42289\tvalid_1's rmse: 3.65635\n",
      "fold 1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[969]\ttraining's rmse: 3.42094\tvalid_1's rmse: 3.64786\n",
      "fold 2\n",
      "Training until validation scores don't improve for 200 rounds.\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "folds = StratifiedKFold(n_splits=5, shuffle = True, random_state=4950)\n",
    "oof = np.zeros(len(train))\n",
    "predictions = np.zeros(len(test))\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train.values, train['outliers'].values)):\n",
    "    \n",
    "    print(\"fold {}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(train.iloc[trn_idx][df_train_columns], label=target.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(train.iloc[val_idx][df_train_columns], label=target.iloc[val_idx])\n",
    "\n",
    "    param ={\n",
    "                'task': 'train',\n",
    "                'boosting': 'goss',\n",
    "                'objective': 'regression',\n",
    "                'metric': 'rmse',\n",
    "                'learning_rate': 0.01,\n",
    "                'subsample': 0.9855232997390695,\n",
    "                'max_depth': 7,\n",
    "                'top_rate': 0.9064148448434349,\n",
    "                'num_leaves': 63,\n",
    "                'min_child_weight': 41.9612869171337,\n",
    "                'other_rate': 0.0721768246018207,\n",
    "                'reg_alpha': 9.677537745007898,\n",
    "                'colsample_bytree': 0.5665320670155495,\n",
    "                'min_split_gain': 9.820197773625843,\n",
    "                'reg_lambda': 8.2532317400459,\n",
    "                'min_data_in_leaf': 21,\n",
    "                'verbose': -1,\n",
    "                'seed':int(2**fold_),\n",
    "                'bagging_seed':int(2**fold_),\n",
    "                'drop_seed':int(2**fold_)\n",
    "                }\n",
    "    \n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=-1, early_stopping_rounds = 200)\n",
    "    oof[val_idx] = clf.predict(train.iloc[val_idx][df_train_columns], num_iteration=clf.best_iteration)\n",
    "    \n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"Feature\"] = df_train_columns\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    \n",
    "    predictions += clf.predict(test[df_train_columns], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "np.sqrt(mean_squared_error(oof, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = (feature_importance_df[[\"Feature\", \"importance\"]]\n",
    "        .groupby(\"Feature\")\n",
    "        .mean()\n",
    "        .sort_values(by=\"importance\", ascending=False)[:1000].index)\n",
    "\n",
    "best_features = feature_importance_df.loc[feature_importance_df.Feature.isin(cols)]\n",
    "\n",
    "plt.figure(figsize=(14,25))\n",
    "sns.barplot(x=\"importance\",\n",
    "            y=\"Feature\",\n",
    "            data=best_features.sort_values(by=\"importance\",\n",
    "                                           ascending=False))\n",
    "plt.title('LightGBM Features (avg over folds)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('lgbm_importances.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [c for c in train.columns if c not in ['card_id', 'first_active_month','target','outliers']]\n",
    "cat_features = [c for c in features if 'feature_' in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'num_leaves': 31,\n",
    "         'min_data_in_leaf': 27, \n",
    "         'objective':'regression',\n",
    "         'max_depth': -1,\n",
    "         'learning_rate': 0.015,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.9,\n",
    "         \"bagging_freq\":4,\n",
    "         \"bagging_fraction\": 0.9,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'rmse',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"verbosity\": -1,\n",
    "         \"nthread\": 4,\n",
    "         \"random_state\": 4950}\n",
    "\n",
    "'''param = {\"bagging_freq\": 4,\n",
    "         \"bagging_fraction\": 0.9,\n",
    "         \"bagging_seed\": 11,\n",
    "         'boosting': 'gbdt',\n",
    "         'objective': 'regression',\n",
    "         'metric': 'rmse',\n",
    "         'learning_rate': 0.01,\n",
    "         'subsample': 0.9855232997390695,\n",
    "         'max_depth': 7,\n",
    "         'top_rate': 0.9064148448434349,\n",
    "         'num_leaves': 63,\n",
    "         'min_child_weight': 41.9612869171337,\n",
    "         'other_rate': 0.0721768246018207,\n",
    "         'reg_alpha': 9.677537745007898,\n",
    "         'colsample_bytree': 0.5665320670155495,\n",
    "         'min_split_gain': 9.820197773625843,\n",
    "         'reg_lambda': 8.2532317400459,\n",
    "         'min_data_in_leaf': 21,\n",
    "         'verbose': -1,\n",
    "         \"verbosity\": -1,\n",
    "         \"nthread\": 4,\n",
    "         \"random_state\": 4950}'''\n",
    "\n",
    "folds = RepeatedKFold(n_splits=5, n_repeats=2, random_state=4950)\n",
    "oof_2 = np.zeros(len(train))\n",
    "predictions_2 = np.zeros(len(test))\n",
    "feature_importance_df_2 = pd.DataFrame()\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train.values, target.values)):\n",
    "    print(\"fold {}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(train.iloc[trn_idx][features], label=target.iloc[trn_idx], categorical_feature=cat_features)\n",
    "    val_data = lgb.Dataset(train.iloc[val_idx][features], label=target.iloc[val_idx], categorical_feature=cat_features)\n",
    "\n",
    "    num_round = 10000\n",
    "    clf_r = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=-1, early_stopping_rounds = 200)\n",
    "    oof_2[val_idx] = clf_r.predict(train.iloc[val_idx][features], num_iteration=clf_r.best_iteration)\n",
    "    \n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"Feature\"] = features\n",
    "    fold_importance_df[\"importance\"] = clf_r.feature_importance()\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df_2 = pd.concat([feature_importance_df_2, fold_importance_df], axis=0)\n",
    "    \n",
    "    predictions_2 += clf_r.predict(test[features], num_iteration=clf_r.best_iteration) / (5 * 2)\n",
    "\n",
    "print(\"CV score: {:<8.5f}\".format(mean_squared_error(oof_2, target)**0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = (feature_importance_df_2[[\"Feature\", \"importance\"]]\n",
    "        .groupby(\"Feature\")\n",
    "        .mean()\n",
    "        .sort_values(by=\"importance\", ascending=False)[:1000].index)\n",
    "\n",
    "best_features = feature_importance_df_2.loc[feature_importance_df_2.Feature.isin(cols)]\n",
    "\n",
    "plt.figure(figsize=(14,25))\n",
    "sns.barplot(x=\"importance\",\n",
    "            y=\"Feature\",\n",
    "            data=best_features.sort_values(by=\"importance\",\n",
    "                                           ascending=False))\n",
    "plt.title('LightGBM Features (avg over folds)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('lgbm_importances.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "train_stack = np.vstack([oof,oof_2]).transpose()\n",
    "test_stack = np.vstack([predictions, predictions_2]).transpose()\n",
    "\n",
    "folds_stack = RepeatedKFold(n_splits=5, n_repeats=1, random_state=4590)\n",
    "oof_stack = np.zeros(train_stack.shape[0])\n",
    "predictions_3 = np.zeros(test_stack.shape[0])\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds_stack.split(train_stack,target)):\n",
    "    print(\"fold {}\".format(fold_))\n",
    "    trn_data, trn_y = train_stack[trn_idx], target.iloc[trn_idx].values\n",
    "    val_data, val_y = train_stack[val_idx], target.iloc[val_idx].values\n",
    "    \n",
    "    clf_3 = BayesianRidge()\n",
    "    clf_3.fit(trn_data, trn_y)\n",
    "    \n",
    "    oof_stack[val_idx] = clf_3.predict(val_data)\n",
    "    predictions_3 += clf_3.predict(test_stack) / 5\n",
    "    \n",
    "np.sqrt(mean_squared_error(target.values, oof_stack))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "sample1 = pd.read_csv(\"3.687.csv\")\n",
    "sample_submission['target'] = predictions_3*0.5 + sample1['target']*0.5\n",
    "sample_submission.to_csv('submission16', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "sample1 = pd.read_csv(\"model-stacking-ensemble-low_features-StratifiedKFold11.csv\")\n",
    "sample2 = pd.read_csv(\"submission2MODEL2.csv\")\n",
    "sample_submission['target'] = sample1['target']*0.5 + sample2['target']*0.5\n",
    "sample_submission.to_csv('submission-final255.csv', index=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
