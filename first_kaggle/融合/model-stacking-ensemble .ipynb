{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, KFold, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge, Lasso, LarsCV, RidgeCV, Lars\n",
    "import warnings\n",
    "import random\n",
    "\n",
    "import datetime\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "import scipy\n",
    "from sklearn.cluster import DBSCAN\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "\n",
    "\n",
    "from keras import Sequential\n",
    "from keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(1)\n",
    "random.seed(1)\n",
    "import time\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "d2a5ca4b3bdef8721219199fa32f8aa269b0a0ea"
   },
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = (8,4)\n",
    "rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "f6cd062118a4b6367524a458e90b41bec8f5a3f8"
   },
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "REF_DATE = datetime.datetime.strptime('2018-12-31', '%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "df04c695a9e7cd33f607417113cb5087236612c2"
   },
   "outputs": [],
   "source": [
    "def skip_func(i, p=0.1, debug=DEBUG):\n",
    "    if debug == True:\n",
    "        return (i>0 and random.random()>p)\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "5ca82b1e416084bd455edc07ed2a0cfd59d3b22f"
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "ec4a0ca3468a03f78c71c23e4731c7e6523df848"
   },
   "outputs": [],
   "source": [
    "def print_null(df):\n",
    "    for col in df:\n",
    "        if df[col].isnull().any():\n",
    "            print('%s has %.0f null values: %.3f%%'%(col, df[col].isnull().sum(), df[col].isnull().sum()/df[col].count()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "82e1cb8c4d33a65b8e4169d4bfea0ab946733748"
   },
   "outputs": [],
   "source": [
    "def impute_na(X_train, df, variable):\n",
    "    # make temporary df copy\n",
    "    temp = df.copy()\n",
    "    \n",
    "    # extract random from train set to fill the na\n",
    "    random_sample = X_train[variable].dropna().sample(temp[variable].isnull().sum(), random_state=0, replace=True)\n",
    "    \n",
    "    # pandas needs to have the same index in order to merge datasets\n",
    "    random_sample.index = temp[temp[variable].isnull()].index\n",
    "    temp.loc[temp[variable].isnull(), variable] = random_sample\n",
    "    return temp[variable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "b003444f6aacc37eab9c69858a37f62ebaaa5fc6"
   },
   "outputs": [],
   "source": [
    "# Clipping outliers\n",
    "def clipping_outliers(X_train, df, var):\n",
    "    IQR = X_train[var].quantile(0.75)-X_train[var].quantile(0.25)\n",
    "    lower_bound = X_train[var].quantile(0.25) - 6*IQR\n",
    "    upper_bound = X_train[var].quantile(0.75) + 6*IQR\n",
    "    no_outliers = len(df[df[var]>upper_bound]) + len(df[df[var]<lower_bound])\n",
    "    print('There are %i outliers in %s: %.3f%%' %(no_outliers, var, no_outliers/len(df)))\n",
    "    df[var] = df[var].clip(lower_bound, upper_bound)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "52c45dad75d35e5eef8d1d280387634709dbc5a4"
   },
   "outputs": [],
   "source": [
    "# Discretize continuous variable\n",
    "def tree_binariser(X_train, X_test, var):\n",
    "    score_ls = []\n",
    "\n",
    "    for tree_depth in [1,2,3,4]:\n",
    "        # call the model\n",
    "        tree_model = DecisionTreeRegressor(max_depth=tree_depth)\n",
    "\n",
    "        # train the model using 3 fold cross validation\n",
    "        scores = cross_val_score(tree_model, X_train[var].to_frame(), X_train['target'], cv=5, scoring='neg_mean_squared_error')\n",
    "        score_ls.append(np.mean(scores))\n",
    "\n",
    "    # find depth with smallest mse\n",
    "    depth = [1,2,3,4][np.argmax(score_ls)]\n",
    "    #print(score_ls, np.argmax(score_ls), depth)\n",
    "\n",
    "    # transform the variable using the tree\n",
    "    tree_model = DecisionTreeRegressor(max_depth=depth)\n",
    "    tree_model.fit(X_train[var].to_frame(), X_train['target'])\n",
    "    X_train[var] = tree_model.predict(X_train[var].to_frame())\n",
    "    #X_val[var] = tree_model.predict(X_val[var].to_frame())\n",
    "    X_test[var] = tree_model.predict(X_test[var].to_frame())\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "092dbb6a27d0c3ec7d582320f3d688092f76065c"
   },
   "source": [
    "<a id='modeling'></a>\n",
    "\n",
    "## Modeling\n",
    "\n",
    "Here we use [out of fold stacking ensemble](https://www.analyticsvidhya.com/blog/2018/06/comprehensive-guide-for-ensemble-models/). The architecture is as followed:\n",
    "\n",
    "**Layer 1**:\n",
    "* 2 lightgbm\n",
    "* 1 xgboost\n",
    "* 1 catboost\n",
    "* 1 dense neural network\n",
    "\n",
    "**Layer 2**:\n",
    "* Lasso regression\n",
    "* Ridge regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = pd.read_csv('low_features3.csv')\n",
    "test = pd.read_csv('test_clean3.csv')\n",
    "#without_outliers\n",
    "'''train = train[train['outliers'] == 0]]'''\n",
    "target = train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATS_EXCLUDED = [\n",
    "    'first_active_month', 'target', 'card_id', 'outliers',\n",
    "    'hist_purchase_date_max', 'hist_purchase_date_min', 'hist_card_id_size',\n",
    "    'new_purchase_date_max', 'new_purchase_date_min', 'new_card_id_size',\n",
    "    'OOF_PRED', 'month_0',\n",
    "    'new_month_lag_min','quarter','new_month_lag_max','hist_month_lag_max','new_month_diff_var'#40\n",
    "    'hist_hour_nunique','new_installments_sum','hist_installments_max','new_subsector_id_nunique',\n",
    "    'new_installments_max','hist_month_lag_min','new_weekofyear_nunique','new_weekend_mean','new_hour_nunique'#30\n",
    "    'hist_subsector_id_nunique']\n",
    "features = [c for c in train.columns if c not in FEATS_EXCLUDED]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "fccf6050cb044feae598977cb37afb62f604529c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"train = train.reset_index(drop=True)\\ntrain = train.drop(columns=['target'])\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''train = train.reset_index(drop=True)\n",
    "train = train.drop(columns=['target'])'''\n",
    "\n",
    "#if DEBUG == False:\n",
    "    #del df_train, df_test\n",
    "    #gc.collect\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c97eb36f6c18eacde14ee15e1d797111df8d8cc5"
   },
   "source": [
    "### First layer\n",
    "#### Tree-based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "883c8336a77e146defbc92ebc4276147af1145cd"
   },
   "outputs": [],
   "source": [
    "# List of model to use\n",
    "if DEBUG == True:\n",
    "    ITERATIONS = 1\n",
    "else:\n",
    "    ITERATIONS = 20000\n",
    "lgb1 = lgb.LGBMRegressor(\n",
    "                        objective= 'regression_l2',\n",
    "                        num_leaves=111,\n",
    "                        max_depth=9,\n",
    "                        learning_rate=0.0035591640406098355,\n",
    "                        n_estimators=ITERATIONS,\n",
    "                        min_child_samples=63,\n",
    "                        subsample=0.6815424617328696,\n",
    "                        subsample_freq=1,\n",
    "                        feature_fraction=0.5020039195436962,\n",
    "                        reg_lambda=8.570580601734264,\n",
    "                        random_state=2779,\n",
    "                        n_jobs=4,\n",
    "                        metrics='rmse',\n",
    "                          device = 'gpu',\n",
    "                          gpu_platform_id= 1,\n",
    "                          gpu_device_id=0,\n",
    "                          num_thread = 1,\n",
    "                          sparse_threshold= 1)\n",
    "\n",
    "lgb2 = lgb.LGBMRegressor(\n",
    "                       device= 'gpu',\n",
    "            gpu_platform_id= 1,\n",
    "            gpu_device_id= 0,\n",
    "            objective= 'regression_l2', \n",
    "            boosting_type= 'gbdt', \n",
    "            n_jobs= 4, max_depth= 7, \n",
    "            n_estimators= ITERATIONS, \n",
    "            subsample_freq= 2, \n",
    "            subsample_for_bin= 200000, \n",
    "            min_data_per_group= 100, \n",
    "            max_cat_to_onehot= 4, \n",
    "            cat_l2= 10.0, \n",
    "            cat_smooth= 10.0, \n",
    "            max_cat_threshold= 32, \n",
    "            metric_freq= 10, \n",
    "            verbosity= -1, \n",
    "            metric= 'rmse', \n",
    "            colsample_bytree= 0.5, \n",
    "            learning_rate= 0.0061033234451294376, \n",
    "            min_child_samples= 80, \n",
    "            min_child_weight= 100.0, \n",
    "            min_split_gain= 1e-06, \n",
    "            num_leaves= 47, \n",
    "            reg_alpha= 10.0, \n",
    "            reg_lambda= 10.0, \n",
    "            subsample= 0.9)\n",
    "\n",
    "xgb1 = xgb.XGBRegressor(learning_rate= 0.5843131085630997,\n",
    "                        booster= 'gbtree',\n",
    "                        alpha = 1.0239095745311145e-08,\n",
    "                        boosting= 'gbdt',\n",
    "                        num_leaves= 31,\n",
    "                        colsample_bytree= 0.5406862297709868,\n",
    "                        subsample= 0.9594952525792275,\n",
    "                        max_depth= 5,\n",
    "                        reg_lambda= 3.143121436123109,\n",
    "                        eta= 2.9162386740282797e-07,\n",
    "                        gamma= 6.015464829655147e-07,\n",
    "                        grow_policy= 'depthwise',\n",
    "                       random_state=2018,\n",
    "                        )\n",
    "\n",
    "cb1 = cb.CatBoostRegressor(iterations=ITERATIONS, learning_rate=0.005, loss_function='RMSE', bootstrap_type='Bernoulli', depth=9, rsm=0.75, subsample=0.75, random_seed=2019, reg_lambda=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "e9b8682c16601ea57fb80535f8cff0ba283ce80d"
   },
   "outputs": [],
   "source": [
    "if DEBUG==True:\n",
    "    N_FOLDS=2\n",
    "else:\n",
    "    N_FOLDS=11\n",
    "layer1_models = [lgb1,  cb1,xgb1 ]#, ada1]\n",
    "layer1_names = ['lightgbm1', 'catboost1','xgboost']#, 'adaboost1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "3e422ec61d402e712fe983df24b4ecb00fb26057"
   },
   "outputs": [],
   "source": [
    "oof_train = np.zeros(shape=(len(train),len(layer1_models)))\n",
    "oof_test = np.zeros(shape=(len(test),len(layer1_models)))\n",
    "\n",
    "# Recording results\n",
    "layer1_score = []\n",
    "feature_importance = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "e52e62067c5e7340d22a69fd0ef93315ea86ff81",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training lightgbm1\n",
      "Fold no 1/11\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's rmse: 3.69122\tvalid_1's rmse: 3.73963\n",
      "[400]\ttraining's rmse: 3.61159\tvalid_1's rmse: 3.68902\n",
      "[600]\ttraining's rmse: 3.56074\tvalid_1's rmse: 3.6677\n",
      "[800]\ttraining's rmse: 3.52292\tvalid_1's rmse: 3.6568\n",
      "[1000]\ttraining's rmse: 3.49334\tvalid_1's rmse: 3.65166\n",
      "[1200]\ttraining's rmse: 3.46782\tvalid_1's rmse: 3.6477\n",
      "[1400]\ttraining's rmse: 3.44558\tvalid_1's rmse: 3.64569\n",
      "[1600]\ttraining's rmse: 3.42506\tvalid_1's rmse: 3.64403\n",
      "[1800]\ttraining's rmse: 3.40565\tvalid_1's rmse: 3.64306\n",
      "[2000]\ttraining's rmse: 3.38668\tvalid_1's rmse: 3.64266\n",
      "[2200]\ttraining's rmse: 3.36965\tvalid_1's rmse: 3.64246\n",
      "[2400]\ttraining's rmse: 3.35239\tvalid_1's rmse: 3.64166\n",
      "[2600]\ttraining's rmse: 3.33584\tvalid_1's rmse: 3.64171\n",
      "[2800]\ttraining's rmse: 3.31946\tvalid_1's rmse: 3.64194\n",
      "Early stopping, best iteration is:\n",
      "[2699]\ttraining's rmse: 3.32751\tvalid_1's rmse: 3.64153\n",
      "Fold no 2/11\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's rmse: 3.69075\tvalid_1's rmse: 3.72991\n",
      "[400]\ttraining's rmse: 3.61093\tvalid_1's rmse: 3.68525\n",
      "[600]\ttraining's rmse: 3.55995\tvalid_1's rmse: 3.66634\n",
      "[800]\ttraining's rmse: 3.5218\tvalid_1's rmse: 3.6579\n",
      "[1000]\ttraining's rmse: 3.49221\tvalid_1's rmse: 3.65366\n",
      "[1200]\ttraining's rmse: 3.46621\tvalid_1's rmse: 3.6507\n",
      "[1400]\ttraining's rmse: 3.44376\tvalid_1's rmse: 3.64874\n",
      "[1600]\ttraining's rmse: 3.4226\tvalid_1's rmse: 3.64695\n",
      "[1800]\ttraining's rmse: 3.4039\tvalid_1's rmse: 3.64611\n",
      "[2000]\ttraining's rmse: 3.38586\tvalid_1's rmse: 3.64529\n",
      "[2200]\ttraining's rmse: 3.36762\tvalid_1's rmse: 3.64462\n",
      "Early stopping, best iteration is:\n",
      "[2180]\ttraining's rmse: 3.36941\tvalid_1's rmse: 3.64451\n",
      "Fold no 3/11\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's rmse: 3.69015\tvalid_1's rmse: 3.7385\n",
      "[400]\ttraining's rmse: 3.6099\tvalid_1's rmse: 3.69561\n",
      "[600]\ttraining's rmse: 3.5586\tvalid_1's rmse: 3.67763\n",
      "[800]\ttraining's rmse: 3.52114\tvalid_1's rmse: 3.66965\n",
      "[1000]\ttraining's rmse: 3.49111\tvalid_1's rmse: 3.66464\n",
      "[1200]\ttraining's rmse: 3.46528\tvalid_1's rmse: 3.66171\n",
      "[1400]\ttraining's rmse: 3.44234\tvalid_1's rmse: 3.65984\n",
      "[1600]\ttraining's rmse: 3.42171\tvalid_1's rmse: 3.65862\n",
      "[1800]\ttraining's rmse: 3.40203\tvalid_1's rmse: 3.65736\n",
      "[2000]\ttraining's rmse: 3.38418\tvalid_1's rmse: 3.65687\n",
      "[2200]\ttraining's rmse: 3.36662\tvalid_1's rmse: 3.65653\n",
      "[2400]\ttraining's rmse: 3.35006\tvalid_1's rmse: 3.65669\n",
      "Early stopping, best iteration is:\n",
      "[2216]\ttraining's rmse: 3.36526\tvalid_1's rmse: 3.65647\n",
      "Fold no 4/11\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's rmse: 3.69166\tvalid_1's rmse: 3.71828\n",
      "[400]\ttraining's rmse: 3.61194\tvalid_1's rmse: 3.67086\n",
      "[600]\ttraining's rmse: 3.56145\tvalid_1's rmse: 3.6504\n",
      "[800]\ttraining's rmse: 3.52404\tvalid_1's rmse: 3.64053\n",
      "[1000]\ttraining's rmse: 3.49476\tvalid_1's rmse: 3.63464\n",
      "[1200]\ttraining's rmse: 3.46902\tvalid_1's rmse: 3.63098\n",
      "[1400]\ttraining's rmse: 3.44716\tvalid_1's rmse: 3.62846\n",
      "[1600]\ttraining's rmse: 3.42644\tvalid_1's rmse: 3.62643\n",
      "[1800]\ttraining's rmse: 3.40725\tvalid_1's rmse: 3.62517\n",
      "[2000]\ttraining's rmse: 3.389\tvalid_1's rmse: 3.62485\n",
      "[2200]\ttraining's rmse: 3.37127\tvalid_1's rmse: 3.62541\n",
      "Early stopping, best iteration is:\n",
      "[2013]\ttraining's rmse: 3.3878\tvalid_1's rmse: 3.62484\n",
      "Fold no 5/11\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's rmse: 3.68982\tvalid_1's rmse: 3.72986\n",
      "[400]\ttraining's rmse: 3.60911\tvalid_1's rmse: 3.688\n",
      "[600]\ttraining's rmse: 3.55755\tvalid_1's rmse: 3.67205\n",
      "[800]\ttraining's rmse: 3.51948\tvalid_1's rmse: 3.66534\n",
      "[1000]\ttraining's rmse: 3.48971\tvalid_1's rmse: 3.66184\n",
      "[1200]\ttraining's rmse: 3.46409\tvalid_1's rmse: 3.65927\n",
      "[1400]\ttraining's rmse: 3.44183\tvalid_1's rmse: 3.65767\n",
      "[1600]\ttraining's rmse: 3.42156\tvalid_1's rmse: 3.6572\n",
      "[1800]\ttraining's rmse: 3.40257\tvalid_1's rmse: 3.65538\n",
      "[2000]\ttraining's rmse: 3.385\tvalid_1's rmse: 3.65517\n",
      "[2200]\ttraining's rmse: 3.36823\tvalid_1's rmse: 3.65462\n",
      "[2400]\ttraining's rmse: 3.35188\tvalid_1's rmse: 3.65421\n",
      "[2600]\ttraining's rmse: 3.33599\tvalid_1's rmse: 3.65402\n",
      "[2800]\ttraining's rmse: 3.31994\tvalid_1's rmse: 3.65388\n",
      "Early stopping, best iteration is:\n",
      "[2704]\ttraining's rmse: 3.32732\tvalid_1's rmse: 3.65357\n",
      "Fold no 6/11\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's rmse: 3.69011\tvalid_1's rmse: 3.73469\n",
      "[400]\ttraining's rmse: 3.60983\tvalid_1's rmse: 3.6899\n",
      "[600]\ttraining's rmse: 3.55905\tvalid_1's rmse: 3.67041\n",
      "[800]\ttraining's rmse: 3.52122\tvalid_1's rmse: 3.66052\n",
      "[1000]\ttraining's rmse: 3.49099\tvalid_1's rmse: 3.65531\n",
      "[1200]\ttraining's rmse: 3.46471\tvalid_1's rmse: 3.6517\n",
      "[1400]\ttraining's rmse: 3.44263\tvalid_1's rmse: 3.65038\n",
      "[1600]\ttraining's rmse: 3.42147\tvalid_1's rmse: 3.64913\n",
      "[1800]\ttraining's rmse: 3.40161\tvalid_1's rmse: 3.64921\n",
      "Early stopping, best iteration is:\n",
      "[1671]\ttraining's rmse: 3.41443\tvalid_1's rmse: 3.64907\n",
      "Fold no 7/11\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's rmse: 3.68953\tvalid_1's rmse: 3.73498\n",
      "[400]\ttraining's rmse: 3.60887\tvalid_1's rmse: 3.69559\n",
      "[600]\ttraining's rmse: 3.55808\tvalid_1's rmse: 3.67939\n",
      "[800]\ttraining's rmse: 3.52041\tvalid_1's rmse: 3.67104\n",
      "[1000]\ttraining's rmse: 3.49092\tvalid_1's rmse: 3.66706\n",
      "[1200]\ttraining's rmse: 3.46575\tvalid_1's rmse: 3.66511\n",
      "[1400]\ttraining's rmse: 3.44272\tvalid_1's rmse: 3.66346\n",
      "[1600]\ttraining's rmse: 3.42171\tvalid_1's rmse: 3.66258\n",
      "[1800]\ttraining's rmse: 3.40304\tvalid_1's rmse: 3.66174\n",
      "[2000]\ttraining's rmse: 3.38472\tvalid_1's rmse: 3.66117\n",
      "[2200]\ttraining's rmse: 3.36697\tvalid_1's rmse: 3.66096\n",
      "[2400]\ttraining's rmse: 3.35069\tvalid_1's rmse: 3.66072\n",
      "[2600]\ttraining's rmse: 3.33399\tvalid_1's rmse: 3.66045\n",
      "[2800]\ttraining's rmse: 3.31737\tvalid_1's rmse: 3.66019\n",
      "[3000]\ttraining's rmse: 3.30119\tvalid_1's rmse: 3.65988\n",
      "[3200]\ttraining's rmse: 3.28542\tvalid_1's rmse: 3.65978\n",
      "Early stopping, best iteration is:\n",
      "[3080]\ttraining's rmse: 3.29474\tvalid_1's rmse: 3.65959\n",
      "Fold no 8/11\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's rmse: 3.69001\tvalid_1's rmse: 3.73497\n",
      "[400]\ttraining's rmse: 3.60929\tvalid_1's rmse: 3.69372\n",
      "[600]\ttraining's rmse: 3.55859\tvalid_1's rmse: 3.67711\n",
      "[800]\ttraining's rmse: 3.52102\tvalid_1's rmse: 3.67003\n",
      "[1000]\ttraining's rmse: 3.49157\tvalid_1's rmse: 3.66576\n",
      "[1200]\ttraining's rmse: 3.46567\tvalid_1's rmse: 3.66313\n",
      "[1400]\ttraining's rmse: 3.44332\tvalid_1's rmse: 3.66119\n",
      "[1600]\ttraining's rmse: 3.42221\tvalid_1's rmse: 3.66088\n",
      "[1800]\ttraining's rmse: 3.40292\tvalid_1's rmse: 3.66089\n",
      "[2000]\ttraining's rmse: 3.38542\tvalid_1's rmse: 3.66029\n",
      "[2200]\ttraining's rmse: 3.36857\tvalid_1's rmse: 3.66025\n",
      "[2400]\ttraining's rmse: 3.35142\tvalid_1's rmse: 3.66093\n",
      "Early stopping, best iteration is:\n",
      "[2227]\ttraining's rmse: 3.36624\tvalid_1's rmse: 3.66024\n",
      "Fold no 9/11\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's rmse: 3.69244\tvalid_1's rmse: 3.71652\n",
      "[400]\ttraining's rmse: 3.61251\tvalid_1's rmse: 3.67325\n",
      "[600]\ttraining's rmse: 3.56145\tvalid_1's rmse: 3.6558\n",
      "[800]\ttraining's rmse: 3.52397\tvalid_1's rmse: 3.64776\n",
      "[1000]\ttraining's rmse: 3.49398\tvalid_1's rmse: 3.64336\n",
      "[1200]\ttraining's rmse: 3.46829\tvalid_1's rmse: 3.64091\n",
      "[1400]\ttraining's rmse: 3.44555\tvalid_1's rmse: 3.63949\n",
      "[1600]\ttraining's rmse: 3.42461\tvalid_1's rmse: 3.63885\n",
      "[1800]\ttraining's rmse: 3.40561\tvalid_1's rmse: 3.63828\n",
      "[2000]\ttraining's rmse: 3.38737\tvalid_1's rmse: 3.63826\n",
      "Early stopping, best iteration is:\n",
      "[1942]\ttraining's rmse: 3.39261\tvalid_1's rmse: 3.63791\n",
      "Fold no 10/11\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's rmse: 3.68934\tvalid_1's rmse: 3.73608\n",
      "[400]\ttraining's rmse: 3.60848\tvalid_1's rmse: 3.6952\n",
      "[600]\ttraining's rmse: 3.55798\tvalid_1's rmse: 3.67964\n",
      "[800]\ttraining's rmse: 3.52042\tvalid_1's rmse: 3.67331\n",
      "[1000]\ttraining's rmse: 3.49055\tvalid_1's rmse: 3.67054\n",
      "[1200]\ttraining's rmse: 3.46453\tvalid_1's rmse: 3.6692\n",
      "[1400]\ttraining's rmse: 3.44173\tvalid_1's rmse: 3.66772\n",
      "[1600]\ttraining's rmse: 3.42087\tvalid_1's rmse: 3.66754\n",
      "[1800]\ttraining's rmse: 3.40145\tvalid_1's rmse: 3.66773\n",
      "Early stopping, best iteration is:\n",
      "[1705]\ttraining's rmse: 3.41033\tvalid_1's rmse: 3.66739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold no 11/11\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's rmse: 3.69183\tvalid_1's rmse: 3.7238\n",
      "[400]\ttraining's rmse: 3.61168\tvalid_1's rmse: 3.67923\n",
      "[600]\ttraining's rmse: 3.56116\tvalid_1's rmse: 3.66034\n",
      "[800]\ttraining's rmse: 3.52369\tvalid_1's rmse: 3.65155\n",
      "[1000]\ttraining's rmse: 3.49413\tvalid_1's rmse: 3.64727\n",
      "[1200]\ttraining's rmse: 3.46857\tvalid_1's rmse: 3.64485\n",
      "[1400]\ttraining's rmse: 3.44569\tvalid_1's rmse: 3.64338\n",
      "[1600]\ttraining's rmse: 3.42499\tvalid_1's rmse: 3.64241\n",
      "[1800]\ttraining's rmse: 3.4056\tvalid_1's rmse: 3.64157\n",
      "[2000]\ttraining's rmse: 3.38729\tvalid_1's rmse: 3.64138\n",
      "Early stopping, best iteration is:\n",
      "[1960]\ttraining's rmse: 3.39095\tvalid_1's rmse: 3.6412\n",
      "Training CV score: 3.64877\n",
      "\n",
      "\n",
      "Training catboost1\n",
      "Fold no 1/11\n",
      "0:\tlearn: 3.8683327\ttest: 3.8683327\ttest1: 3.8756430\tbest: 3.8756430 (0)\ttotal: 130ms\tremaining: 43m 19s\n",
      "200:\tlearn: 3.6985592\ttest: 3.6985592\ttest1: 3.7319542\tbest: 3.7319542 (200)\ttotal: 17.3s\tremaining: 28m 21s\n",
      "400:\tlearn: 3.6409426\ttest: 3.6409426\ttest1: 3.6951406\tbest: 3.6951406 (400)\ttotal: 35.3s\tremaining: 28m 46s\n",
      "600:\tlearn: 3.6083623\ttest: 3.6083623\ttest1: 3.6817902\tbest: 3.6817902 (600)\ttotal: 53.5s\tremaining: 28m 46s\n",
      "800:\tlearn: 3.5825964\ttest: 3.5825964\ttest1: 3.6741562\tbest: 3.6741562 (800)\ttotal: 1m 11s\tremaining: 28m 29s\n",
      "1000:\tlearn: 3.5604510\ttest: 3.5604510\ttest1: 3.6698020\tbest: 3.6697661 (999)\ttotal: 1m 29s\tremaining: 28m 17s\n",
      "1200:\tlearn: 3.5408442\ttest: 3.5408442\ttest1: 3.6662956\tbest: 3.6662899 (1197)\ttotal: 1m 46s\tremaining: 27m 39s\n",
      "1400:\tlearn: 3.5221447\ttest: 3.5221447\ttest1: 3.6636103\tbest: 3.6636068 (1399)\ttotal: 2m 2s\tremaining: 27m 4s\n",
      "1600:\tlearn: 3.5046911\ttest: 3.5046911\ttest1: 3.6618537\tbest: 3.6618537 (1600)\ttotal: 2m 18s\tremaining: 26m 36s\n",
      "1800:\tlearn: 3.4882332\ttest: 3.4882332\ttest1: 3.6605506\tbest: 3.6605506 (1800)\ttotal: 2m 35s\tremaining: 26m 8s\n",
      "2000:\tlearn: 3.4720401\ttest: 3.4720401\ttest1: 3.6592893\tbest: 3.6592609 (1992)\ttotal: 2m 51s\tremaining: 25m 43s\n",
      "2200:\tlearn: 3.4563744\ttest: 3.4563744\ttest1: 3.6581800\tbest: 3.6581800 (2200)\ttotal: 3m 8s\tremaining: 25m 20s\n",
      "2400:\tlearn: 3.4406053\ttest: 3.4406053\ttest1: 3.6574983\tbest: 3.6574027 (2380)\ttotal: 3m 24s\tremaining: 25m 1s\n",
      "2600:\tlearn: 3.4250693\ttest: 3.4250693\ttest1: 3.6567593\tbest: 3.6567593 (2600)\ttotal: 3m 41s\tremaining: 24m 39s\n",
      "2800:\tlearn: 3.4098461\ttest: 3.4098461\ttest1: 3.6560390\tbest: 3.6560288 (2796)\ttotal: 3m 57s\tremaining: 24m 16s\n",
      "3000:\tlearn: 3.3934596\ttest: 3.3934596\ttest1: 3.6556697\tbest: 3.6555263 (2906)\ttotal: 4m 13s\tremaining: 23m 56s\n",
      "3200:\tlearn: 3.3774645\ttest: 3.3774645\ttest1: 3.6552560\tbest: 3.6552006 (3185)\ttotal: 4m 30s\tremaining: 23m 37s\n",
      "3400:\tlearn: 3.3613064\ttest: 3.3613064\ttest1: 3.6546541\tbest: 3.6546463 (3399)\ttotal: 4m 46s\tremaining: 23m 20s\n",
      "3600:\tlearn: 3.3463096\ttest: 3.3463096\ttest1: 3.6541356\tbest: 3.6540816 (3587)\ttotal: 5m 3s\tremaining: 23m 1s\n",
      "3800:\tlearn: 3.3306209\ttest: 3.3306209\ttest1: 3.6538263\tbest: 3.6536795 (3735)\ttotal: 5m 19s\tremaining: 22m 41s\n",
      "4000:\tlearn: 3.3154810\ttest: 3.3154810\ttest1: 3.6534061\tbest: 3.6533391 (3973)\ttotal: 5m 36s\tremaining: 22m 23s\n",
      "4200:\tlearn: 3.3009746\ttest: 3.3009746\ttest1: 3.6531629\tbest: 3.6530768 (4192)\ttotal: 5m 52s\tremaining: 22m 5s\n",
      "4400:\tlearn: 3.2858018\ttest: 3.2858018\ttest1: 3.6529727\tbest: 3.6528491 (4384)\ttotal: 6m 8s\tremaining: 21m 46s\n",
      "4600:\tlearn: 3.2711122\ttest: 3.2711122\ttest1: 3.6523449\tbest: 3.6523197 (4553)\ttotal: 6m 24s\tremaining: 21m 27s\n",
      "4800:\tlearn: 3.2571011\ttest: 3.2571011\ttest1: 3.6521168\tbest: 3.6520525 (4708)\ttotal: 6m 41s\tremaining: 21m 9s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 3.652052463\n",
      "bestIteration = 4708\n",
      "\n",
      "Shrink model to first 4709 iterations.\n",
      "Fold no 2/11\n",
      "0:\tlearn: 3.8696753\ttest: 3.8696753\ttest1: 3.8616851\tbest: 3.8616851 (0)\ttotal: 92.1ms\tremaining: 30m 41s\n",
      "200:\tlearn: 3.7024613\ttest: 3.7024613\ttest1: 3.6983534\tbest: 3.6983534 (200)\ttotal: 17.3s\tremaining: 28m 20s\n",
      "400:\tlearn: 3.6447352\ttest: 3.6447352\ttest1: 3.6557355\tbest: 3.6557355 (400)\ttotal: 34.3s\tremaining: 27m 56s\n",
      "600:\tlearn: 3.6115654\ttest: 3.6115654\ttest1: 3.6393573\tbest: 3.6393573 (600)\ttotal: 51.2s\tremaining: 27m 32s\n",
      "800:\tlearn: 3.5861559\ttest: 3.5861559\ttest1: 3.6308280\tbest: 3.6308280 (800)\ttotal: 1m 7s\tremaining: 27m 9s\n",
      "1000:\tlearn: 3.5644959\ttest: 3.5644959\ttest1: 3.6259231\tbest: 3.6259231 (1000)\ttotal: 1m 24s\tremaining: 26m 44s\n",
      "1200:\tlearn: 3.5443959\ttest: 3.5443959\ttest1: 3.6226419\tbest: 3.6226419 (1200)\ttotal: 1m 40s\tremaining: 26m 20s\n",
      "1400:\tlearn: 3.5260669\ttest: 3.5260669\ttest1: 3.6204094\tbest: 3.6204094 (1400)\ttotal: 1m 57s\tremaining: 25m 57s\n",
      "1600:\tlearn: 3.5073121\ttest: 3.5073121\ttest1: 3.6178194\tbest: 3.6178194 (1600)\ttotal: 2m 13s\tremaining: 25m 38s\n",
      "1800:\tlearn: 3.4903037\ttest: 3.4903037\ttest1: 3.6158897\tbest: 3.6158897 (1800)\ttotal: 2m 30s\tremaining: 25m 18s\n",
      "2000:\tlearn: 3.4738600\ttest: 3.4738600\ttest1: 3.6148235\tbest: 3.6147927 (1997)\ttotal: 2m 46s\tremaining: 24m 59s\n",
      "2200:\tlearn: 3.4579183\ttest: 3.4579183\ttest1: 3.6137811\tbest: 3.6137244 (2185)\ttotal: 3m 3s\tremaining: 24m 41s\n",
      "2400:\tlearn: 3.4424923\ttest: 3.4424923\ttest1: 3.6131426\tbest: 3.6131426 (2400)\ttotal: 3m 19s\tremaining: 24m 22s\n",
      "2600:\tlearn: 3.4267008\ttest: 3.4267008\ttest1: 3.6124941\tbest: 3.6124691 (2569)\ttotal: 3m 35s\tremaining: 24m 2s\n",
      "2800:\tlearn: 3.4107463\ttest: 3.4107463\ttest1: 3.6119614\tbest: 3.6119560 (2799)\ttotal: 3m 51s\tremaining: 23m 43s\n",
      "3000:\tlearn: 3.3945400\ttest: 3.3945400\ttest1: 3.6113702\tbest: 3.6113480 (2962)\ttotal: 4m 8s\tremaining: 23m 28s\n",
      "3200:\tlearn: 3.3788773\ttest: 3.3788773\ttest1: 3.6107700\tbest: 3.6106618 (3178)\ttotal: 4m 25s\tremaining: 23m 12s\n",
      "3400:\tlearn: 3.3628232\ttest: 3.3628232\ttest1: 3.6108207\tbest: 3.6105216 (3329)\ttotal: 4m 42s\tremaining: 22m 59s\n",
      "3600:\tlearn: 3.3472365\ttest: 3.3472365\ttest1: 3.6103501\tbest: 3.6103164 (3596)\ttotal: 5m 2s\tremaining: 22m 56s\n",
      "3800:\tlearn: 3.3319685\ttest: 3.3319685\ttest1: 3.6104535\tbest: 3.6101448 (3690)\ttotal: 5m 20s\tremaining: 22m 44s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 3.61014475\n",
      "bestIteration = 3690\n",
      "\n",
      "Shrink model to first 3691 iterations.\n",
      "Fold no 3/11\n",
      "0:\tlearn: 3.8696617\ttest: 3.8696617\ttest1: 3.8621713\tbest: 3.8621713 (0)\ttotal: 96.5ms\tremaining: 32m 9s\n",
      "200:\tlearn: 3.7005122\ttest: 3.7005122\ttest1: 3.7016003\tbest: 3.7016003 (200)\ttotal: 19.9s\tremaining: 32m 37s\n",
      "400:\tlearn: 3.6427949\ttest: 3.6427949\ttest1: 3.6623303\tbest: 3.6623303 (400)\ttotal: 39.5s\tremaining: 32m 11s\n",
      "600:\tlearn: 3.6093703\ttest: 3.6093703\ttest1: 3.6482013\tbest: 3.6482013 (600)\ttotal: 57.7s\tremaining: 31m 3s\n",
      "800:\tlearn: 3.5834675\ttest: 3.5834675\ttest1: 3.6411195\tbest: 3.6411195 (800)\ttotal: 1m 15s\tremaining: 30m 13s\n",
      "1000:\tlearn: 3.5613828\ttest: 3.5613828\ttest1: 3.6369480\tbest: 3.6369480 (1000)\ttotal: 1m 34s\tremaining: 29m 44s\n",
      "1200:\tlearn: 3.5413775\ttest: 3.5413775\ttest1: 3.6336738\tbest: 3.6336738 (1200)\ttotal: 1m 52s\tremaining: 29m 18s\n",
      "1400:\tlearn: 3.5234427\ttest: 3.5234427\ttest1: 3.6309968\tbest: 3.6309968 (1400)\ttotal: 2m 10s\tremaining: 28m 51s\n",
      "1600:\tlearn: 3.5052075\ttest: 3.5052075\ttest1: 3.6288597\tbest: 3.6288597 (1600)\ttotal: 2m 30s\tremaining: 28m 45s\n",
      "1800:\tlearn: 3.4881715\ttest: 3.4881715\ttest1: 3.6277847\tbest: 3.6277766 (1799)\ttotal: 2m 49s\tremaining: 28m 35s\n",
      "2000:\tlearn: 3.4711926\ttest: 3.4711926\ttest1: 3.6266632\tbest: 3.6266323 (1992)\ttotal: 3m 9s\tremaining: 28m 21s\n",
      "2200:\tlearn: 3.4553892\ttest: 3.4553892\ttest1: 3.6259788\tbest: 3.6259368 (2168)\ttotal: 3m 26s\tremaining: 27m 53s\n",
      "2400:\tlearn: 3.4394090\ttest: 3.4394090\ttest1: 3.6253346\tbest: 3.6252093 (2320)\ttotal: 3m 44s\tremaining: 27m 22s\n",
      "2600:\tlearn: 3.4236698\ttest: 3.4236698\ttest1: 3.6245124\tbest: 3.6244256 (2594)\ttotal: 4m\tremaining: 26m 49s\n",
      "2800:\tlearn: 3.4067127\ttest: 3.4067127\ttest1: 3.6237863\tbest: 3.6237553 (2798)\ttotal: 4m 17s\tremaining: 26m 19s\n",
      "3000:\tlearn: 3.3906005\ttest: 3.3906005\ttest1: 3.6230884\tbest: 3.6230837 (2999)\ttotal: 4m 33s\tremaining: 25m 51s\n",
      "3200:\tlearn: 3.3742712\ttest: 3.3742712\ttest1: 3.6225332\tbest: 3.6224601 (3178)\ttotal: 4m 50s\tremaining: 25m 25s\n",
      "3400:\tlearn: 3.3579527\ttest: 3.3579527\ttest1: 3.6223937\tbest: 3.6223478 (3359)\ttotal: 5m 7s\tremaining: 24m 59s\n",
      "3600:\tlearn: 3.3424043\ttest: 3.3424043\ttest1: 3.6221469\tbest: 3.6220896 (3589)\ttotal: 5m 24s\tremaining: 24m 35s\n",
      "3800:\tlearn: 3.3271195\ttest: 3.3271195\ttest1: 3.6218545\tbest: 3.6218427 (3761)\ttotal: 5m 41s\tremaining: 24m 14s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000:\tlearn: 3.3113002\ttest: 3.3113002\ttest1: 3.6212153\tbest: 3.6211764 (3947)\ttotal: 5m 58s\tremaining: 23m 54s\n",
      "4200:\tlearn: 3.2960452\ttest: 3.2960452\ttest1: 3.6210786\tbest: 3.6209660 (4180)\ttotal: 6m 16s\tremaining: 23m 36s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 3.620965992\n",
      "bestIteration = 4180\n",
      "\n",
      "Shrink model to first 4181 iterations.\n",
      "Fold no 4/11\n",
      "0:\tlearn: 3.8686235\ttest: 3.8686235\ttest1: 3.8733507\tbest: 3.8733507 (0)\ttotal: 82.7ms\tremaining: 27m 33s\n",
      "200:\tlearn: 3.6963700\ttest: 3.6963700\ttest1: 3.7310561\tbest: 3.7310561 (200)\ttotal: 18.6s\tremaining: 30m 27s\n",
      "400:\tlearn: 3.6386565\ttest: 3.6386565\ttest1: 3.6983044\tbest: 3.6983044 (400)\ttotal: 35.9s\tremaining: 29m 16s\n",
      "600:\tlearn: 3.6045996\ttest: 3.6045996\ttest1: 3.6865734\tbest: 3.6865625 (599)\ttotal: 54s\tremaining: 29m 2s\n",
      "800:\tlearn: 3.5789929\ttest: 3.5789929\ttest1: 3.6800033\tbest: 3.6799777 (799)\ttotal: 1m 11s\tremaining: 28m 32s\n",
      "1000:\tlearn: 3.5575707\ttest: 3.5575707\ttest1: 3.6753262\tbest: 3.6753262 (1000)\ttotal: 1m 28s\tremaining: 27m 55s\n",
      "1200:\tlearn: 3.5378597\ttest: 3.5378597\ttest1: 3.6721134\tbest: 3.6721134 (1200)\ttotal: 1m 45s\tremaining: 27m 23s\n",
      "1400:\tlearn: 3.5190701\ttest: 3.5190701\ttest1: 3.6694233\tbest: 3.6694233 (1400)\ttotal: 2m 1s\tremaining: 26m 52s\n",
      "1600:\tlearn: 3.5012700\ttest: 3.5012700\ttest1: 3.6679521\tbest: 3.6679521 (1600)\ttotal: 2m 17s\tremaining: 26m 22s\n",
      "1800:\tlearn: 3.4849332\ttest: 3.4849332\ttest1: 3.6667594\tbest: 3.6667594 (1800)\ttotal: 2m 34s\tremaining: 26m\n",
      "2000:\tlearn: 3.4688923\ttest: 3.4688923\ttest1: 3.6658492\tbest: 3.6656889 (1921)\ttotal: 2m 51s\tremaining: 25m 43s\n",
      "2200:\tlearn: 3.4526224\ttest: 3.4526224\ttest1: 3.6649807\tbest: 3.6648418 (2193)\ttotal: 3m 10s\tremaining: 25m 41s\n",
      "2400:\tlearn: 3.4372889\ttest: 3.4372889\ttest1: 3.6638940\tbest: 3.6638835 (2398)\ttotal: 3m 27s\tremaining: 25m 23s\n",
      "2600:\tlearn: 3.4216111\ttest: 3.4216111\ttest1: 3.6631987\tbest: 3.6631799 (2596)\ttotal: 3m 45s\tremaining: 25m 5s\n",
      "2800:\tlearn: 3.4059933\ttest: 3.4059933\ttest1: 3.6624452\tbest: 3.6623899 (2778)\ttotal: 4m 4s\tremaining: 25m\n",
      "3000:\tlearn: 3.3895020\ttest: 3.3895020\ttest1: 3.6621610\tbest: 3.6620212 (2975)\ttotal: 4m 21s\tremaining: 24m 40s\n",
      "3200:\tlearn: 3.3732495\ttest: 3.3732495\ttest1: 3.6612664\tbest: 3.6612664 (3200)\ttotal: 4m 39s\tremaining: 24m 24s\n",
      "3400:\tlearn: 3.3573816\ttest: 3.3573816\ttest1: 3.6609828\tbest: 3.6609077 (3393)\ttotal: 4m 55s\tremaining: 24m 3s\n",
      "3600:\tlearn: 3.3418205\ttest: 3.3418205\ttest1: 3.6599292\tbest: 3.6598986 (3575)\ttotal: 5m 12s\tremaining: 23m 41s\n",
      "3800:\tlearn: 3.3265350\ttest: 3.3265350\ttest1: 3.6595414\tbest: 3.6593649 (3767)\ttotal: 5m 29s\tremaining: 23m 22s\n",
      "4000:\tlearn: 3.3117657\ttest: 3.3117657\ttest1: 3.6589481\tbest: 3.6589481 (4000)\ttotal: 5m 45s\tremaining: 23m 1s\n",
      "4200:\tlearn: 3.2962004\ttest: 3.2962004\ttest1: 3.6587467\tbest: 3.6586840 (4154)\ttotal: 6m 1s\tremaining: 22m 39s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 3.658684016\n",
      "bestIteration = 4154\n",
      "\n",
      "Shrink model to first 4155 iterations.\n",
      "Fold no 5/11\n",
      "0:\tlearn: 3.8674530\ttest: 3.8674530\ttest1: 3.8843871\tbest: 3.8843871 (0)\ttotal: 88.3ms\tremaining: 29m 26s\n",
      "200:\tlearn: 3.6993161\ttest: 3.6993161\ttest1: 3.7253155\tbest: 3.7253155 (200)\ttotal: 17.2s\tremaining: 28m 12s\n",
      "400:\tlearn: 3.6420989\ttest: 3.6420989\ttest1: 3.6848551\tbest: 3.6848551 (400)\ttotal: 34s\tremaining: 27m 42s\n",
      "600:\tlearn: 3.6094792\ttest: 3.6094792\ttest1: 3.6698345\tbest: 3.6698345 (600)\ttotal: 50.5s\tremaining: 27m 10s\n",
      "800:\tlearn: 3.5829407\ttest: 3.5829407\ttest1: 3.6619712\tbest: 3.6619712 (800)\ttotal: 1m 6s\tremaining: 26m 44s\n",
      "1000:\tlearn: 3.5609497\ttest: 3.5609497\ttest1: 3.6564195\tbest: 3.6564195 (1000)\ttotal: 1m 23s\tremaining: 26m 23s\n",
      "1200:\tlearn: 3.5408318\ttest: 3.5408318\ttest1: 3.6522680\tbest: 3.6522680 (1200)\ttotal: 1m 39s\tremaining: 25m 59s\n",
      "1400:\tlearn: 3.5227570\ttest: 3.5227570\ttest1: 3.6490453\tbest: 3.6490453 (1400)\ttotal: 1m 55s\tremaining: 25m 37s\n",
      "1600:\tlearn: 3.5050142\ttest: 3.5050142\ttest1: 3.6465091\tbest: 3.6465091 (1600)\ttotal: 2m 12s\tremaining: 25m 17s\n",
      "1800:\tlearn: 3.4886625\ttest: 3.4886625\ttest1: 3.6451130\tbest: 3.6451130 (1800)\ttotal: 2m 28s\tremaining: 24m 57s\n",
      "2000:\tlearn: 3.4726702\ttest: 3.4726702\ttest1: 3.6432106\tbest: 3.6432106 (2000)\ttotal: 2m 44s\tremaining: 24m 37s\n",
      "2200:\tlearn: 3.4565139\ttest: 3.4565139\ttest1: 3.6411654\tbest: 3.6410926 (2196)\ttotal: 3m\tremaining: 24m 19s\n",
      "2400:\tlearn: 3.4410594\ttest: 3.4410594\ttest1: 3.6396907\tbest: 3.6396854 (2397)\ttotal: 3m 16s\tremaining: 24m\n",
      "2600:\tlearn: 3.4253435\ttest: 3.4253435\ttest1: 3.6385732\tbest: 3.6384815 (2589)\ttotal: 3m 32s\tremaining: 23m 41s\n",
      "2800:\tlearn: 3.4099146\ttest: 3.4099146\ttest1: 3.6382205\tbest: 3.6380774 (2765)\ttotal: 3m 48s\tremaining: 23m 22s\n",
      "3000:\tlearn: 3.3940838\ttest: 3.3940838\ttest1: 3.6377917\tbest: 3.6376851 (2975)\ttotal: 4m 4s\tremaining: 23m 5s\n",
      "3200:\tlearn: 3.3772541\ttest: 3.3772541\ttest1: 3.6372401\tbest: 3.6372332 (3198)\ttotal: 4m 20s\tremaining: 22m 47s\n",
      "3400:\tlearn: 3.3615797\ttest: 3.3615797\ttest1: 3.6361188\tbest: 3.6361188 (3400)\ttotal: 4m 36s\tremaining: 22m 30s\n",
      "3600:\tlearn: 3.3460730\ttest: 3.3460730\ttest1: 3.6352308\tbest: 3.6352093 (3596)\ttotal: 4m 52s\tremaining: 22m 13s\n",
      "3800:\tlearn: 3.3313636\ttest: 3.3313636\ttest1: 3.6349028\tbest: 3.6347942 (3777)\ttotal: 5m 9s\tremaining: 21m 57s\n",
      "4000:\tlearn: 3.3162248\ttest: 3.3162248\ttest1: 3.6347946\tbest: 3.6346682 (3921)\ttotal: 5m 25s\tremaining: 21m 40s\n",
      "4200:\tlearn: 3.3019653\ttest: 3.3019653\ttest1: 3.6341424\tbest: 3.6341424 (4200)\ttotal: 5m 41s\tremaining: 21m 24s\n",
      "4400:\tlearn: 3.2872216\ttest: 3.2872216\ttest1: 3.6336395\tbest: 3.6335970 (4396)\ttotal: 5m 57s\tremaining: 21m 7s\n",
      "4600:\tlearn: 3.2723151\ttest: 3.2723151\ttest1: 3.6329195\tbest: 3.6329195 (4600)\ttotal: 6m 13s\tremaining: 20m 51s\n",
      "4800:\tlearn: 3.2576093\ttest: 3.2576093\ttest1: 3.6330964\tbest: 3.6328292 (4747)\ttotal: 6m 29s\tremaining: 20m 34s\n",
      "5000:\tlearn: 3.2437808\ttest: 3.2437808\ttest1: 3.6327978\tbest: 3.6326851 (4918)\ttotal: 6m 46s\tremaining: 20m 17s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 3.632685082\n",
      "bestIteration = 4918\n",
      "\n",
      "Shrink model to first 4919 iterations.\n",
      "Fold no 6/11\n",
      "0:\tlearn: 3.8693542\ttest: 3.8693542\ttest1: 3.8652965\tbest: 3.8652965 (0)\ttotal: 87.1ms\tremaining: 29m 1s\n",
      "200:\tlearn: 3.6962826\ttest: 3.6962826\ttest1: 3.7295930\tbest: 3.7295930 (200)\ttotal: 17.3s\tremaining: 28m 21s\n",
      "400:\tlearn: 3.6364112\ttest: 3.6364112\ttest1: 3.7000347\tbest: 3.7000347 (400)\ttotal: 34.1s\tremaining: 27m 45s\n",
      "600:\tlearn: 3.6020741\ttest: 3.6020741\ttest1: 3.6905464\tbest: 3.6905464 (600)\ttotal: 50.8s\tremaining: 27m 18s\n",
      "800:\tlearn: 3.5753030\ttest: 3.5753030\ttest1: 3.6861222\tbest: 3.6860908 (797)\ttotal: 1m 7s\tremaining: 26m 50s\n",
      "1000:\tlearn: 3.5530764\ttest: 3.5530764\ttest1: 3.6842638\tbest: 3.6841512 (994)\ttotal: 1m 23s\tremaining: 26m 23s\n",
      "1200:\tlearn: 3.5320515\ttest: 3.5320515\ttest1: 3.6830055\tbest: 3.6829913 (1197)\ttotal: 1m 39s\tremaining: 25m 59s\n",
      "1400:\tlearn: 3.5134938\ttest: 3.5134938\ttest1: 3.6819328\tbest: 3.6819227 (1396)\ttotal: 1m 56s\tremaining: 25m 40s\n",
      "1600:\tlearn: 3.4957195\ttest: 3.4957195\ttest1: 3.6812193\tbest: 3.6812068 (1595)\ttotal: 2m 12s\tremaining: 25m 20s\n",
      "1800:\tlearn: 3.4797243\ttest: 3.4797243\ttest1: 3.6801917\tbest: 3.6801917 (1800)\ttotal: 2m 28s\tremaining: 25m\n",
      "2000:\tlearn: 3.4640243\ttest: 3.4640243\ttest1: 3.6791615\tbest: 3.6791389 (1996)\ttotal: 2m 44s\tremaining: 24m 41s\n",
      "2200:\tlearn: 3.4477108\ttest: 3.4477108\ttest1: 3.6786048\tbest: 3.6785655 (2189)\ttotal: 3m\tremaining: 24m 22s\n",
      "2400:\tlearn: 3.4318103\ttest: 3.4318103\ttest1: 3.6781140\tbest: 3.6780207 (2386)\ttotal: 3m 17s\tremaining: 24m 4s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 3.67802073\n",
      "bestIteration = 2386\n",
      "\n",
      "Shrink model to first 2387 iterations.\n",
      "Fold no 7/11\n",
      "0:\tlearn: 3.8676274\ttest: 3.8676274\ttest1: 3.8820668\tbest: 3.8820668 (0)\ttotal: 83.8ms\tremaining: 27m 56s\n",
      "200:\tlearn: 3.6966161\ttest: 3.6966161\ttest1: 3.7411211\tbest: 3.7411211 (200)\ttotal: 17.5s\tremaining: 28m 46s\n",
      "400:\tlearn: 3.6380529\ttest: 3.6380529\ttest1: 3.7098439\tbest: 3.7098439 (400)\ttotal: 34.4s\tremaining: 28m\n",
      "600:\tlearn: 3.6037066\ttest: 3.6037066\ttest1: 3.6983057\tbest: 3.6983057 (600)\ttotal: 51s\tremaining: 27m 24s\n",
      "800:\tlearn: 3.5782445\ttest: 3.5782445\ttest1: 3.6924881\tbest: 3.6924876 (799)\ttotal: 1m 7s\tremaining: 26m 51s\n",
      "1000:\tlearn: 3.5562249\ttest: 3.5562249\ttest1: 3.6884152\tbest: 3.6884152 (1000)\ttotal: 1m 23s\tremaining: 26m 27s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200:\tlearn: 3.5357527\ttest: 3.5357527\ttest1: 3.6861612\tbest: 3.6861184 (1191)\ttotal: 1m 39s\tremaining: 26m 4s\n",
      "1400:\tlearn: 3.5172071\ttest: 3.5172071\ttest1: 3.6845172\tbest: 3.6845172 (1400)\ttotal: 1m 56s\tremaining: 25m 41s\n",
      "1600:\tlearn: 3.4995774\ttest: 3.4995774\ttest1: 3.6838206\tbest: 3.6838110 (1524)\ttotal: 2m 12s\tremaining: 25m 23s\n",
      "1800:\tlearn: 3.4829021\ttest: 3.4829021\ttest1: 3.6828659\tbest: 3.6828487 (1797)\ttotal: 2m 28s\tremaining: 25m 4s\n",
      "2000:\tlearn: 3.4669326\ttest: 3.4669326\ttest1: 3.6825085\tbest: 3.6823409 (1938)\ttotal: 2m 45s\tremaining: 24m 45s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 3.682340888\n",
      "bestIteration = 1938\n",
      "\n",
      "Shrink model to first 1939 iterations.\n",
      "Fold no 8/11\n",
      "0:\tlearn: 3.8698388\ttest: 3.8698388\ttest1: 3.8603294\tbest: 3.8603294 (0)\ttotal: 81.5ms\tremaining: 27m 10s\n",
      "200:\tlearn: 3.6987557\ttest: 3.6987557\ttest1: 3.7191708\tbest: 3.7191708 (200)\ttotal: 17.4s\tremaining: 28m 34s\n",
      "400:\tlearn: 3.6404198\ttest: 3.6404198\ttest1: 3.6852921\tbest: 3.6852921 (400)\ttotal: 34.5s\tremaining: 28m 3s\n",
      "600:\tlearn: 3.6054395\ttest: 3.6054395\ttest1: 3.6725400\tbest: 3.6725400 (600)\ttotal: 51.3s\tremaining: 27m 34s\n",
      "800:\tlearn: 3.5790283\ttest: 3.5790283\ttest1: 3.6666626\tbest: 3.6666626 (800)\ttotal: 1m 7s\tremaining: 27m 8s\n",
      "1000:\tlearn: 3.5557974\ttest: 3.5557974\ttest1: 3.6626273\tbest: 3.6626273 (1000)\ttotal: 1m 24s\tremaining: 26m 42s\n",
      "1200:\tlearn: 3.5356110\ttest: 3.5356110\ttest1: 3.6594898\tbest: 3.6594898 (1200)\ttotal: 1m 40s\tremaining: 26m 17s\n",
      "1400:\tlearn: 3.5167166\ttest: 3.5167166\ttest1: 3.6572201\tbest: 3.6572201 (1400)\ttotal: 1m 57s\tremaining: 25m 56s\n",
      "1600:\tlearn: 3.4985167\ttest: 3.4985167\ttest1: 3.6557287\tbest: 3.6557287 (1600)\ttotal: 2m 13s\tremaining: 25m 35s\n",
      "1800:\tlearn: 3.4814261\ttest: 3.4814261\ttest1: 3.6544546\tbest: 3.6544346 (1798)\ttotal: 2m 29s\tremaining: 25m 15s\n",
      "2000:\tlearn: 3.4643509\ttest: 3.4643509\ttest1: 3.6530757\tbest: 3.6530632 (1993)\ttotal: 2m 46s\tremaining: 24m 55s\n",
      "2200:\tlearn: 3.4486348\ttest: 3.4486348\ttest1: 3.6522973\tbest: 3.6522634 (2170)\ttotal: 3m 2s\tremaining: 24m 37s\n",
      "2400:\tlearn: 3.4326817\ttest: 3.4326817\ttest1: 3.6517132\tbest: 3.6516798 (2397)\ttotal: 3m 18s\tremaining: 24m 17s\n",
      "2600:\tlearn: 3.4167277\ttest: 3.4167277\ttest1: 3.6513549\tbest: 3.6512258 (2556)\ttotal: 3m 34s\tremaining: 23m 58s\n",
      "2800:\tlearn: 3.4009489\ttest: 3.4009489\ttest1: 3.6508315\tbest: 3.6508054 (2798)\ttotal: 3m 51s\tremaining: 23m 38s\n",
      "3000:\tlearn: 3.3848862\ttest: 3.3848862\ttest1: 3.6503829\tbest: 3.6503504 (2994)\ttotal: 4m 7s\tremaining: 23m 19s\n",
      "3200:\tlearn: 3.3684921\ttest: 3.3684921\ttest1: 3.6497345\tbest: 3.6497123 (3187)\ttotal: 4m 23s\tremaining: 23m 2s\n",
      "3400:\tlearn: 3.3525524\ttest: 3.3525524\ttest1: 3.6495373\tbest: 3.6495366 (3390)\ttotal: 4m 39s\tremaining: 22m 44s\n",
      "3600:\tlearn: 3.3374066\ttest: 3.3374066\ttest1: 3.6494322\tbest: 3.6494322 (3600)\ttotal: 4m 56s\tremaining: 22m 29s\n",
      "3800:\tlearn: 3.3217131\ttest: 3.3217131\ttest1: 3.6496965\tbest: 3.6494322 (3600)\ttotal: 5m 12s\tremaining: 22m 13s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 3.64943215\n",
      "bestIteration = 3600\n",
      "\n",
      "Shrink model to first 3601 iterations.\n",
      "Fold no 9/11\n",
      "0:\tlearn: 3.8699676\ttest: 3.8699676\ttest1: 3.8602845\tbest: 3.8602845 (0)\ttotal: 86.1ms\tremaining: 28m 42s\n",
      "200:\tlearn: 3.6972103\ttest: 3.6972103\ttest1: 3.7191923\tbest: 3.7191923 (200)\ttotal: 17.5s\tremaining: 28m 43s\n",
      "400:\tlearn: 3.6381241\ttest: 3.6381241\ttest1: 3.6893996\tbest: 3.6893996 (400)\ttotal: 34.4s\tremaining: 28m 1s\n",
      "600:\tlearn: 3.6036142\ttest: 3.6036142\ttest1: 3.6791311\tbest: 3.6791311 (600)\ttotal: 51.1s\tremaining: 27m 30s\n",
      "800:\tlearn: 3.5768397\ttest: 3.5768397\ttest1: 3.6741556\tbest: 3.6741522 (799)\ttotal: 1m 7s\tremaining: 27m 2s\n",
      "1000:\tlearn: 3.5542339\ttest: 3.5542339\ttest1: 3.6711186\tbest: 3.6711186 (1000)\ttotal: 1m 24s\tremaining: 26m 41s\n",
      "1200:\tlearn: 3.5348419\ttest: 3.5348419\ttest1: 3.6688175\tbest: 3.6688175 (1200)\ttotal: 1m 40s\tremaining: 26m 16s\n",
      "1400:\tlearn: 3.5167725\ttest: 3.5167725\ttest1: 3.6675010\tbest: 3.6675010 (1400)\ttotal: 1m 57s\tremaining: 25m 53s\n",
      "1600:\tlearn: 3.4994346\ttest: 3.4994346\ttest1: 3.6662294\tbest: 3.6661595 (1593)\ttotal: 2m 13s\tremaining: 25m 31s\n",
      "1800:\tlearn: 3.4826426\ttest: 3.4826426\ttest1: 3.6653552\tbest: 3.6653552 (1800)\ttotal: 2m 29s\tremaining: 25m 11s\n",
      "2000:\tlearn: 3.4664958\ttest: 3.4664958\ttest1: 3.6641547\tbest: 3.6641547 (2000)\ttotal: 2m 45s\tremaining: 24m 51s\n",
      "2200:\tlearn: 3.4507139\ttest: 3.4507139\ttest1: 3.6638000\tbest: 3.6638000 (2200)\ttotal: 3m 1s\tremaining: 24m 31s\n",
      "2400:\tlearn: 3.4348877\ttest: 3.4348877\ttest1: 3.6632635\tbest: 3.6630745 (2332)\ttotal: 3m 18s\tremaining: 24m 12s\n",
      "2600:\tlearn: 3.4191694\ttest: 3.4191694\ttest1: 3.6630910\tbest: 3.6629976 (2481)\ttotal: 3m 34s\tremaining: 23m 53s\n",
      "2800:\tlearn: 3.4030785\ttest: 3.4030785\ttest1: 3.6625035\tbest: 3.6625035 (2800)\ttotal: 3m 50s\tremaining: 23m 35s\n",
      "3000:\tlearn: 3.3873739\ttest: 3.3873739\ttest1: 3.6622886\tbest: 3.6621209 (2929)\ttotal: 4m 6s\tremaining: 23m 18s\n",
      "3200:\tlearn: 3.3708586\ttest: 3.3708586\ttest1: 3.6620114\tbest: 3.6619452 (3179)\ttotal: 4m 23s\tremaining: 23m 1s\n",
      "3400:\tlearn: 3.3552325\ttest: 3.3552325\ttest1: 3.6614661\tbest: 3.6614475 (3398)\ttotal: 4m 39s\tremaining: 22m 44s\n",
      "3600:\tlearn: 3.3402422\ttest: 3.3402422\ttest1: 3.6609428\tbest: 3.6609264 (3597)\ttotal: 4m 55s\tremaining: 22m 26s\n",
      "3800:\tlearn: 3.3253435\ttest: 3.3253435\ttest1: 3.6606282\tbest: 3.6605849 (3787)\ttotal: 5m 12s\tremaining: 22m 10s\n",
      "4000:\tlearn: 3.3106349\ttest: 3.3106349\ttest1: 3.6603697\tbest: 3.6602295 (3963)\ttotal: 5m 28s\tremaining: 21m 53s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 3.660229503\n",
      "bestIteration = 3963\n",
      "\n",
      "Shrink model to first 3964 iterations.\n",
      "Fold no 10/11\n",
      "0:\tlearn: 3.8689401\ttest: 3.8689401\ttest1: 3.8700622\tbest: 3.8700622 (0)\ttotal: 90.2ms\tremaining: 30m 3s\n",
      "200:\tlearn: 3.7001914\ttest: 3.7001914\ttest1: 3.7144847\tbest: 3.7144847 (200)\ttotal: 17.4s\tremaining: 28m 31s\n",
      "400:\tlearn: 3.6422172\ttest: 3.6422172\ttest1: 3.6751393\tbest: 3.6751393 (400)\ttotal: 34.3s\tremaining: 27m 54s\n",
      "600:\tlearn: 3.6082914\ttest: 3.6082914\ttest1: 3.6601398\tbest: 3.6601398 (600)\ttotal: 51s\tremaining: 27m 25s\n",
      "800:\tlearn: 3.5831204\ttest: 3.5831204\ttest1: 3.6524671\tbest: 3.6524671 (800)\ttotal: 1m 7s\tremaining: 27m\n",
      "1000:\tlearn: 3.5603528\ttest: 3.5603528\ttest1: 3.6472751\tbest: 3.6472751 (1000)\ttotal: 1m 24s\tremaining: 26m 35s\n",
      "1200:\tlearn: 3.5403783\ttest: 3.5403783\ttest1: 3.6438235\tbest: 3.6438205 (1199)\ttotal: 1m 40s\tremaining: 26m 12s\n",
      "1400:\tlearn: 3.5218048\ttest: 3.5218048\ttest1: 3.6412508\tbest: 3.6412508 (1400)\ttotal: 1m 56s\tremaining: 25m 50s\n",
      "1600:\tlearn: 3.5044388\ttest: 3.5044388\ttest1: 3.6389578\tbest: 3.6389578 (1600)\ttotal: 2m 13s\tremaining: 25m 29s\n",
      "1800:\tlearn: 3.4876351\ttest: 3.4876351\ttest1: 3.6370834\tbest: 3.6370834 (1800)\ttotal: 2m 29s\tremaining: 25m 9s\n",
      "2000:\tlearn: 3.4718265\ttest: 3.4718265\ttest1: 3.6353785\tbest: 3.6353553 (1995)\ttotal: 2m 45s\tremaining: 24m 49s\n",
      "2200:\tlearn: 3.4558256\ttest: 3.4558256\ttest1: 3.6341392\tbest: 3.6341392 (2200)\ttotal: 3m 1s\tremaining: 24m 30s\n",
      "2400:\tlearn: 3.4406477\ttest: 3.4406477\ttest1: 3.6331558\tbest: 3.6331558 (2400)\ttotal: 3m 18s\tremaining: 24m 12s\n",
      "2600:\tlearn: 3.4249209\ttest: 3.4249209\ttest1: 3.6324483\tbest: 3.6324063 (2596)\ttotal: 3m 34s\tremaining: 23m 52s\n",
      "2800:\tlearn: 3.4096089\ttest: 3.4096089\ttest1: 3.6318545\tbest: 3.6317372 (2756)\ttotal: 3m 50s\tremaining: 23m 34s\n",
      "3000:\tlearn: 3.3934163\ttest: 3.3934163\ttest1: 3.6313679\tbest: 3.6313679 (3000)\ttotal: 4m 6s\tremaining: 23m 15s\n",
      "3200:\tlearn: 3.3771711\ttest: 3.3771711\ttest1: 3.6306694\tbest: 3.6306427 (3193)\ttotal: 4m 22s\tremaining: 22m 57s\n",
      "3400:\tlearn: 3.3617422\ttest: 3.3617422\ttest1: 3.6303220\tbest: 3.6303121 (3370)\ttotal: 4m 38s\tremaining: 22m 39s\n",
      "3600:\tlearn: 3.3461497\ttest: 3.3461497\ttest1: 3.6296295\tbest: 3.6295989 (3596)\ttotal: 4m 54s\tremaining: 22m 22s\n",
      "3800:\tlearn: 3.3307221\ttest: 3.3307221\ttest1: 3.6287421\tbest: 3.6285877 (3776)\ttotal: 5m 11s\tremaining: 22m 5s\n",
      "4000:\tlearn: 3.3157260\ttest: 3.3157260\ttest1: 3.6284542\tbest: 3.6282413 (3914)\ttotal: 5m 27s\tremaining: 21m 48s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 3.628241264\n",
      "bestIteration = 3914\n",
      "\n",
      "Shrink model to first 3915 iterations.\n",
      "Fold no 11/11\n",
      "0:\tlearn: 3.8694399\ttest: 3.8694399\ttest1: 3.8650356\tbest: 3.8650356 (0)\ttotal: 89.3ms\tremaining: 29m 46s\n",
      "200:\tlearn: 3.6983140\ttest: 3.6983140\ttest1: 3.7239375\tbest: 3.7239375 (200)\ttotal: 17.8s\tremaining: 29m 13s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400:\tlearn: 3.6401132\ttest: 3.6401132\ttest1: 3.6922386\tbest: 3.6922386 (400)\ttotal: 35.1s\tremaining: 28m 36s\n",
      "600:\tlearn: 3.6069285\ttest: 3.6069285\ttest1: 3.6814671\tbest: 3.6814671 (600)\ttotal: 52.3s\tremaining: 28m 8s\n",
      "800:\tlearn: 3.5805951\ttest: 3.5805951\ttest1: 3.6768462\tbest: 3.6768462 (800)\ttotal: 1m 9s\tremaining: 27m 37s\n",
      "1000:\tlearn: 3.5579131\ttest: 3.5579131\ttest1: 3.6732711\tbest: 3.6732711 (1000)\ttotal: 1m 26s\tremaining: 27m 13s\n",
      "1200:\tlearn: 3.5380310\ttest: 3.5380310\ttest1: 3.6717771\tbest: 3.6717523 (1179)\ttotal: 1m 42s\tremaining: 26m 47s\n",
      "1400:\tlearn: 3.5186686\ttest: 3.5186686\ttest1: 3.6704298\tbest: 3.6704143 (1383)\ttotal: 1m 59s\tremaining: 26m 23s\n",
      "1600:\tlearn: 3.5003592\ttest: 3.5003592\ttest1: 3.6696865\tbest: 3.6696243 (1595)\ttotal: 2m 15s\tremaining: 26m 1s\n",
      "1800:\tlearn: 3.4836509\ttest: 3.4836509\ttest1: 3.6690123\tbest: 3.6689053 (1771)\ttotal: 2m 32s\tremaining: 25m 40s\n",
      "2000:\tlearn: 3.4669201\ttest: 3.4669201\ttest1: 3.6683431\tbest: 3.6683431 (2000)\ttotal: 2m 49s\tremaining: 25m 20s\n",
      "2200:\tlearn: 3.4512867\ttest: 3.4512867\ttest1: 3.6675792\tbest: 3.6675304 (2190)\ttotal: 3m 5s\tremaining: 25m 1s\n",
      "2400:\tlearn: 3.4350801\ttest: 3.4350801\ttest1: 3.6669136\tbest: 3.6668217 (2389)\ttotal: 3m 22s\tremaining: 24m 43s\n",
      "2600:\tlearn: 3.4190517\ttest: 3.4190517\ttest1: 3.6666572\tbest: 3.6665360 (2574)\ttotal: 3m 38s\tremaining: 24m 23s\n",
      "2800:\tlearn: 3.4036546\ttest: 3.4036546\ttest1: 3.6659846\tbest: 3.6659829 (2799)\ttotal: 3m 55s\tremaining: 24m 4s\n",
      "3000:\tlearn: 3.3866209\ttest: 3.3866209\ttest1: 3.6654308\tbest: 3.6653563 (2969)\ttotal: 4m 11s\tremaining: 23m 45s\n",
      "3200:\tlearn: 3.3705955\ttest: 3.3705955\ttest1: 3.6645822\tbest: 3.6645822 (3200)\ttotal: 4m 28s\tremaining: 23m 26s\n",
      "3400:\tlearn: 3.3546521\ttest: 3.3546521\ttest1: 3.6643614\tbest: 3.6640594 (3318)\ttotal: 4m 44s\tremaining: 23m 8s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 3.664059405\n",
      "bestIteration = 3318\n",
      "\n",
      "Shrink model to first 3319 iterations.\n",
      "Training CV score: 3.64887\n",
      "\n",
      "\n",
      "Training xgboost\n",
      "Fold no 1/11\n",
      "[0]\tvalidation_0-rmse:3.76744\tvalidation_1-rmse:3.77411\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 200 rounds.\n",
      "[99]\tvalidation_0-rmse:3.28217\tvalidation_1-rmse:3.75234\n",
      "Fold no 2/11\n",
      "[0]\tvalidation_0-rmse:3.76987\tvalidation_1-rmse:3.77165\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 200 rounds.\n",
      "[99]\tvalidation_0-rmse:3.26675\tvalidation_1-rmse:3.74313\n",
      "Fold no 3/11\n",
      "[0]\tvalidation_0-rmse:3.76879\tvalidation_1-rmse:3.76856\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 200 rounds.\n",
      "[99]\tvalidation_0-rmse:3.26889\tvalidation_1-rmse:3.71072\n",
      "Fold no 4/11\n",
      "[0]\tvalidation_0-rmse:3.76827\tvalidation_1-rmse:3.77872\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 200 rounds.\n",
      "[99]\tvalidation_0-rmse:3.26359\tvalidation_1-rmse:3.75173\n",
      "Fold no 5/11\n",
      "[0]\tvalidation_0-rmse:3.76773\tvalidation_1-rmse:3.79189\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 200 rounds.\n",
      "[99]\tvalidation_0-rmse:3.27431\tvalidation_1-rmse:3.73016\n",
      "Fold no 6/11\n",
      "[0]\tvalidation_0-rmse:3.77947\tvalidation_1-rmse:3.79583\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 200 rounds.\n",
      "[99]\tvalidation_0-rmse:3.26134\tvalidation_1-rmse:3.79565\n",
      "Fold no 7/11\n",
      "[0]\tvalidation_0-rmse:3.77852\tvalidation_1-rmse:3.77449\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 200 rounds.\n",
      "[99]\tvalidation_0-rmse:3.25574\tvalidation_1-rmse:3.78829\n",
      "Fold no 8/11\n",
      "[0]\tvalidation_0-rmse:3.75672\tvalidation_1-rmse:3.76346\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 200 rounds.\n",
      "[99]\tvalidation_0-rmse:3.25487\tvalidation_1-rmse:3.77455\n",
      "Fold no 9/11\n",
      "[0]\tvalidation_0-rmse:3.75816\tvalidation_1-rmse:3.75642\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 200 rounds.\n",
      "[99]\tvalidation_0-rmse:3.26309\tvalidation_1-rmse:3.72894\n",
      "Fold no 10/11\n",
      "[0]\tvalidation_0-rmse:3.75694\tvalidation_1-rmse:3.76595\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 200 rounds.\n",
      "[99]\tvalidation_0-rmse:3.25372\tvalidation_1-rmse:3.77874\n",
      "Fold no 11/11\n",
      "[0]\tvalidation_0-rmse:3.75728\tvalidation_1-rmse:3.763\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 200 rounds.\n",
      "[99]\tvalidation_0-rmse:3.23314\tvalidation_1-rmse:3.78874\n",
      "Training CV score: 3.67919\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(layer1_models)):\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    print('\\n')\n",
    "    name = layer1_names[i]\n",
    "    model = layer1_models[i]\n",
    "    folds = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=2019+i)\n",
    "    print('Training %s' %name)\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(train[features], train['outliers'])):\n",
    "        print('Fold no %i/%i'%(fold_+1,N_FOLDS))\n",
    "        trn_data = train[features].iloc[trn_idx]\n",
    "        trn_label = train['target'].iloc[trn_idx]\n",
    "        val_data = train[features].iloc[val_idx]\n",
    "        val_label = train['target'].iloc[val_idx]\n",
    "        if 'ada' in name:\n",
    "            model.fit(X=trn_data, y=trn_label)\n",
    "        else:\n",
    "            model.fit(X=trn_data, y=trn_label,\n",
    "                     eval_set=[(trn_data, trn_label), (val_data, val_label)],\n",
    "                     verbose=200,\n",
    "                     early_stopping_rounds=200)\n",
    "\n",
    "        oof_train[val_idx,i] = model.predict(val_data)\n",
    "        oof_test[:,i] += model.predict(test[features])/N_FOLDS\n",
    "        \n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = features\n",
    "        fold_importance_df[\"importance\"] = model.feature_importances_\n",
    "        fold_importance_df[\"fold\"] = fold_ + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "        \n",
    "    score = mean_squared_error(oof_train[:,i], target)**0.5\n",
    "    layer1_score.append(score)\n",
    "    feature_importance.append(feature_importance_df)\n",
    "    print('Training CV score: %.5f' %score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exchange two models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CV score for LGB: 3.64666\n"
     ]
    }
   ],
   "source": [
    "oof_preds=np.loadtxt('lgb_oof_preds.csv',delimiter=',')\n",
    "sub_preds=np.loadtxt('lgb_sub_preds.csv',delimiter=',')\n",
    "\n",
    "score = score = mean_squared_error(target, oof_preds) ** .5\n",
    "print('Training CV score for LGB: %.5f' %score)\n",
    "layer1_names.append('LGB')\n",
    "layer1_score.append(score)\n",
    "\n",
    "oof_preds = oof_preds[:, np.newaxis]\n",
    "sub_preds = sub_preds[:, np.newaxis]\n",
    "oof_train = np.hstack((oof_train, oof_preds))\n",
    "oof_test = np.hstack((oof_test, sub_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CV score for XGB: 3.64800\n"
     ]
    }
   ],
   "source": [
    "oof_preds=np.loadtxt('xgb_oof_preds.csv',delimiter=',')\n",
    "sub_preds=np.loadtxt('xgb_sub_preds.csv',delimiter=',')\n",
    "\n",
    "score = score = mean_squared_error(target, oof_preds) ** .5\n",
    "print('Training CV score for XGB: %.5f' %score)\n",
    "layer1_names.append('XGB')\n",
    "layer1_score.append(score)\n",
    "\n",
    "oof_preds = oof_preds[:, np.newaxis]\n",
    "sub_preds = sub_preds[:, np.newaxis]\n",
    "oof_train = np.hstack((oof_train, oof_preds))\n",
    "oof_test = np.hstack((oof_test, sub_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lightgbm1', 'catboost1', 'xgboost', 'LGB', 'XGB']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer1_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6e8c116f803514c5e401fa8fbd964f84435ab383"
   },
   "source": [
    "#### Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "c3e4f3592cafb0ca9a306d80406948061466281e"
   },
   "outputs": [],
   "source": [
    "# Preparation\n",
    "\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler, Imputer\n",
    "K.set_session(tf.Session(config=tf.ConfigProto(device_count={'gpu':0})))\n",
    "\n",
    "\n",
    "oof_train_nn = np.zeros(shape=(len(train),1))\n",
    "oof_test_nn = np.zeros(shape=(len(test),1))\n",
    "\n",
    "'''train = train.dropna(axis=1)\n",
    "train = train.fillna(0)\n",
    "obs = train.isnull().sum().sort_values(ascending = False)\n",
    "percent = round(train.isnull().sum().sort_values(ascending = False)/len(train)*100, 2)\n",
    "pd.concat([obs, percent], axis = 1,keys= ['Number of Observations', 'Percent'])'''\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#\n",
    "train[features] = train[features][~train[features].isin([np.nan, np.inf, -np.inf]).any(1)]\n",
    "train[features] = train[features].fillna(0)\n",
    "test[features] = test[features][~test[features].isin([np.nan, np.inf, -np.inf]).any(1)]\n",
    "test[features] = test[features].fillna(0)\n",
    "\n",
    "scaler.fit(train[features])\n",
    "\n",
    "X_train = scaler.transform(train.iloc[:][features].values)\n",
    "X_test = scaler.transform(test.iloc[:][features].values)\n",
    "\n",
    "X_train = pd.DataFrame(X_train, index=train[features].index, columns=train[features].columns)\n",
    "X_test = pd.DataFrame(X_test, index=test[features].index, columns=test[features].columns)\n",
    "\n",
    "\n",
    "if DEBUG == True:\n",
    "    EPOCHS=1\n",
    "else:\n",
    "    EPOCHS=30 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "10c67ec65417f7cf55121c68ac53faf24ea6d430"
   },
   "outputs": [],
   "source": [
    "def nn_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim = input_shape, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "early_stop = EarlyStopping(patience=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "18dbcae699e892c1bab619559d1cb1d62f99b572",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold no 1/11\n",
      "Train on 183560 samples, validate on 18357 samples\n",
      "Epoch 1/30\n",
      "183560/183560 [==============================] - 4s 22us/step - loss: 14.5422 - val_loss: 14.9987\n",
      "Epoch 2/30\n",
      "183560/183560 [==============================] - 3s 17us/step - loss: 13.9851 - val_loss: 15.1668\n",
      "Epoch 3/30\n",
      "183560/183560 [==============================] - 3s 18us/step - loss: 13.8038 - val_loss: 14.2617\n",
      "Epoch 4/30\n",
      "183560/183560 [==============================] - 3s 17us/step - loss: 13.7406 - val_loss: 14.0218\n",
      "Epoch 5/30\n",
      "183560/183560 [==============================] - 3s 17us/step - loss: 13.6550 - val_loss: 14.1257\n",
      "Epoch 6/30\n",
      "183560/183560 [==============================] - 3s 17us/step - loss: 13.5972 - val_loss: 14.2521\n",
      "Epoch 7/30\n",
      "183560/183560 [==============================] - 3s 17us/step - loss: 13.5710 - val_loss: 14.1962\n",
      "Epoch 8/30\n",
      "183560/183560 [==============================] - 3s 17us/step - loss: 13.5035 - val_loss: 14.2027\n",
      "Epoch 9/30\n",
      "183560/183560 [==============================] - 3s 17us/step - loss: 13.5131 - val_loss: 14.7439\n",
      "Epoch 00009: early stopping\n",
      "Fold no 2/11\n",
      "Train on 183561 samples, validate on 18356 samples\n",
      "Epoch 1/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 14.4771 - val_loss: 14.9338\n",
      "Epoch 2/30\n",
      "183561/183561 [==============================] - 3s 17us/step - loss: 13.8613 - val_loss: 14.7921\n",
      "Epoch 3/30\n",
      "183561/183561 [==============================] - 3s 17us/step - loss: 13.6646 - val_loss: 14.6787\n",
      "Epoch 4/30\n",
      "183561/183561 [==============================] - 3s 17us/step - loss: 13.5923 - val_loss: 14.6344\n",
      "Epoch 5/30\n",
      "183561/183561 [==============================] - 3s 17us/step - loss: 13.5098 - val_loss: 14.6100\n",
      "Epoch 6/30\n",
      "183561/183561 [==============================] - 3s 17us/step - loss: 13.4527 - val_loss: 14.5801\n",
      "Epoch 7/30\n",
      "183561/183561 [==============================] - 3s 17us/step - loss: 13.4228 - val_loss: 14.5453\n",
      "Epoch 8/30\n",
      "183561/183561 [==============================] - 3s 17us/step - loss: 13.3852 - val_loss: 14.6521\n",
      "Epoch 9/30\n",
      "183561/183561 [==============================] - 3s 17us/step - loss: 13.3677 - val_loss: 14.4692\n",
      "Epoch 10/30\n",
      "183561/183561 [==============================] - 3s 17us/step - loss: 13.3228 - val_loss: 14.5660\n",
      "Epoch 11/30\n",
      "183561/183561 [==============================] - 3s 17us/step - loss: 13.2553 - val_loss: 14.5591\n",
      "Epoch 12/30\n",
      "183561/183561 [==============================] - 3s 17us/step - loss: 13.2507 - val_loss: 14.5237\n",
      "Epoch 13/30\n",
      "183561/183561 [==============================] - 3s 17us/step - loss: 13.2200 - val_loss: 14.5441\n",
      "Epoch 14/30\n",
      "183561/183561 [==============================] - 3s 17us/step - loss: 13.2080 - val_loss: 14.6289\n",
      "Epoch 00014: early stopping\n",
      "Fold no 3/11\n",
      "Train on 183561 samples, validate on 18356 samples\n",
      "Epoch 1/30\n",
      "183561/183561 [==============================] - 3s 19us/step - loss: 14.4675 - val_loss: 14.1029\n",
      "Epoch 2/30\n",
      "183561/183561 [==============================] - 3s 17us/step - loss: 13.9290 - val_loss: 13.9432\n",
      "Epoch 3/30\n",
      "183561/183561 [==============================] - 3s 17us/step - loss: 13.7681 - val_loss: 13.8764\n",
      "Epoch 4/30\n",
      "183561/183561 [==============================] - 3s 17us/step - loss: 13.6372 - val_loss: 13.8980\n",
      "Epoch 5/30\n",
      "183561/183561 [==============================] - 3s 17us/step - loss: 13.5790 - val_loss: 13.9097\n",
      "Epoch 6/30\n",
      "183561/183561 [==============================] - 3s 17us/step - loss: 13.5434 - val_loss: 13.7936\n",
      "Epoch 7/30\n",
      "183561/183561 [==============================] - 3s 17us/step - loss: 13.4879 - val_loss: 13.8282\n",
      "Epoch 8/30\n",
      "183561/183561 [==============================] - 3s 17us/step - loss: 13.4862 - val_loss: 13.7156\n",
      "Epoch 9/30\n",
      "183561/183561 [==============================] - 3s 17us/step - loss: 13.4251 - val_loss: 13.6601\n",
      "Epoch 10/30\n",
      "183561/183561 [==============================] - 3s 17us/step - loss: 13.3900 - val_loss: 13.7772\n",
      "Epoch 11/30\n",
      "183561/183561 [==============================] - 3s 17us/step - loss: 13.3260 - val_loss: 13.6990\n",
      "Epoch 12/30\n",
      "183561/183561 [==============================] - 3s 17us/step - loss: 13.3359 - val_loss: 13.7414\n",
      "Epoch 13/30\n",
      "183561/183561 [==============================] - 3s 17us/step - loss: 13.2485 - val_loss: 13.8119\n",
      "Epoch 14/30\n",
      "183561/183561 [==============================] - 3s 17us/step - loss: 13.2425 - val_loss: 13.7103\n",
      "Epoch 00014: early stopping\n",
      "Fold no 4/11\n",
      "Train on 183561 samples, validate on 18356 samples\n",
      "Epoch 1/30\n",
      "183561/183561 [==============================] - 4s 19us/step - loss: 14.5933 - val_loss: 13.3134\n",
      "Epoch 2/30\n",
      "183561/183561 [==============================] - 3s 17us/step - loss: 14.0478 - val_loss: 13.0097\n",
      "Epoch 3/30\n",
      "183561/183561 [==============================] - 3s 17us/step - loss: 13.8899 - val_loss: 13.0072\n",
      "Epoch 4/30\n",
      "183561/183561 [==============================] - 3s 17us/step - loss: 13.7959 - val_loss: 12.9295\n",
      "Epoch 5/30\n",
      "183561/183561 [==============================] - 3s 17us/step - loss: 13.7289 - val_loss: 12.8658\n",
      "Epoch 6/30\n",
      "183561/183561 [==============================] - 3s 17us/step - loss: 13.6526 - val_loss: 12.8093\n",
      "Epoch 7/30\n",
      "183561/183561 [==============================] - 3s 17us/step - loss: 13.6224 - val_loss: 12.8574\n",
      "Epoch 8/30\n",
      "183561/183561 [==============================] - 3s 17us/step - loss: 13.5790 - val_loss: 12.8354\n",
      "Epoch 9/30\n",
      "183561/183561 [==============================] - 3s 17us/step - loss: 13.5265 - val_loss: 12.8390\n",
      "Epoch 10/30\n",
      "183561/183561 [==============================] - 3s 17us/step - loss: 13.5083 - val_loss: 12.7718\n",
      "Epoch 11/30\n",
      "183561/183561 [==============================] - 3s 17us/step - loss: 13.4615 - val_loss: 12.7648\n",
      "Epoch 12/30\n",
      "183561/183561 [==============================] - 3s 17us/step - loss: 13.4132 - val_loss: 12.7706\n",
      "Epoch 13/30\n",
      "183561/183561 [==============================] - 3s 17us/step - loss: 13.4338 - val_loss: 12.7240\n",
      "Epoch 14/30\n",
      "183561/183561 [==============================] - 3s 17us/step - loss: 13.3835 - val_loss: 12.8063\n",
      "Epoch 15/30\n",
      "183561/183561 [==============================] - 3s 17us/step - loss: 13.3148 - val_loss: 12.8471\n",
      "Epoch 16/30\n",
      "183561/183561 [==============================] - 3s 17us/step - loss: 13.2554 - val_loss: 12.8155\n",
      "Epoch 17/30\n",
      "183561/183561 [==============================] - 3s 17us/step - loss: 13.2863 - val_loss: 12.8249\n",
      "Epoch 18/30\n",
      "183561/183561 [==============================] - 3s 17us/step - loss: 13.2466 - val_loss: 12.8236\n",
      "Epoch 00018: early stopping\n",
      "Fold no 5/11\n",
      "Train on 183561 samples, validate on 18356 samples\n",
      "Epoch 1/30\n",
      "183561/183561 [==============================] - 4s 19us/step - loss: 14.5253 - val_loss: 13.5890\n",
      "Epoch 2/30\n",
      "183561/183561 [==============================] - 3s 17us/step - loss: 13.9680 - val_loss: 13.4368\n",
      "Epoch 3/30\n",
      "183561/183561 [==============================] - 3s 17us/step - loss: 13.8111 - val_loss: 13.3417\n",
      "Epoch 4/30\n",
      "183561/183561 [==============================] - 3s 17us/step - loss: 13.7109 - val_loss: 13.3615\n",
      "Epoch 5/30\n",
      "183561/183561 [==============================] - 3s 17us/step - loss: 13.6390 - val_loss: 13.2835\n",
      "Epoch 6/30\n",
      "183561/183561 [==============================] - 3s 17us/step - loss: 13.5964 - val_loss: 13.2595\n",
      "Epoch 7/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.5566 - val_loss: 13.2038\n",
      "Epoch 8/30\n",
      "183561/183561 [==============================] - 3s 17us/step - loss: 13.4672 - val_loss: 13.2268\n",
      "Epoch 9/30\n",
      "183561/183561 [==============================] - 3s 17us/step - loss: 13.4790 - val_loss: 13.2994\n",
      "Epoch 10/30\n",
      "183561/183561 [==============================] - 3s 17us/step - loss: 13.4675 - val_loss: 13.2738\n",
      "Epoch 11/30\n",
      "183561/183561 [==============================] - 3s 17us/step - loss: 13.4103 - val_loss: 13.2084\n",
      "Epoch 12/30\n",
      "183561/183561 [==============================] - 3s 17us/step - loss: 13.3997 - val_loss: 13.2241\n",
      "Epoch 00012: early stopping\n",
      "Fold no 6/11\n",
      "Train on 183561 samples, validate on 18356 samples\n",
      "Epoch 1/30\n",
      "183561/183561 [==============================] - 4s 20us/step - loss: 14.6132 - val_loss: 13.1136\n",
      "Epoch 2/30\n",
      "183561/183561 [==============================] - 3s 17us/step - loss: 14.0386 - val_loss: 13.0294\n",
      "Epoch 3/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.8630 - val_loss: 13.0581\n",
      "Epoch 4/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183561/183561 [==============================] - 3s 17us/step - loss: 13.7294 - val_loss: 12.9718\n",
      "Epoch 5/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.6722 - val_loss: 12.9196\n",
      "Epoch 6/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.6481 - val_loss: 12.9789\n",
      "Epoch 7/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.5644 - val_loss: 12.9904\n",
      "Epoch 8/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.5467 - val_loss: 12.8963\n",
      "Epoch 9/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.4750 - val_loss: 12.9047\n",
      "Epoch 10/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.4541 - val_loss: 12.9000\n",
      "Epoch 11/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.4238 - val_loss: 12.9173\n",
      "Epoch 12/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.3696 - val_loss: 12.9753\n",
      "Epoch 13/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.3664 - val_loss: 12.9136\n",
      "Epoch 00013: early stopping\n",
      "Fold no 7/11\n",
      "Train on 183561 samples, validate on 18356 samples\n",
      "Epoch 1/30\n",
      "183561/183561 [==============================] - 4s 20us/step - loss: 14.5298 - val_loss: 14.1567\n",
      "Epoch 2/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.9278 - val_loss: 13.9703\n",
      "Epoch 3/30\n",
      "183561/183561 [==============================] - 3s 17us/step - loss: 13.8151 - val_loss: 13.8688\n",
      "Epoch 4/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.6675 - val_loss: 13.8735\n",
      "Epoch 5/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.5964 - val_loss: 13.7836\n",
      "Epoch 6/30\n",
      "183561/183561 [==============================] - 3s 17us/step - loss: 13.5340 - val_loss: 13.7795\n",
      "Epoch 7/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.5443 - val_loss: 13.8512\n",
      "Epoch 8/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.4792 - val_loss: 13.7612\n",
      "Epoch 9/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.4424 - val_loss: 13.7846\n",
      "Epoch 10/30\n",
      "183561/183561 [==============================] - 3s 17us/step - loss: 13.4046 - val_loss: 13.8158\n",
      "Epoch 11/30\n",
      "183561/183561 [==============================] - 3s 17us/step - loss: 13.4071 - val_loss: 13.8186\n",
      "Epoch 12/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.3788 - val_loss: 13.7425\n",
      "Epoch 13/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.2945 - val_loss: 13.6801\n",
      "Epoch 14/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.2692 - val_loss: 13.7785\n",
      "Epoch 15/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.2562 - val_loss: 13.7134\n",
      "Epoch 16/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.2256 - val_loss: 13.9108\n",
      "Epoch 17/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.2202 - val_loss: 13.9598\n",
      "Epoch 18/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.1488 - val_loss: 13.7592\n",
      "Epoch 00018: early stopping\n",
      "Fold no 8/11\n",
      "Train on 183561 samples, validate on 18356 samples\n",
      "Epoch 1/30\n",
      "183561/183561 [==============================] - 4s 20us/step - loss: 14.5801 - val_loss: 14.3877\n",
      "Epoch 2/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.9044 - val_loss: 14.2040\n",
      "Epoch 3/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.7375 - val_loss: 14.1601\n",
      "Epoch 4/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.6519 - val_loss: 14.0943\n",
      "Epoch 5/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.6002 - val_loss: 14.1267\n",
      "Epoch 6/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.5086 - val_loss: 14.0414\n",
      "Epoch 7/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.4824 - val_loss: 14.0601\n",
      "Epoch 8/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.4126 - val_loss: 13.9969\n",
      "Epoch 9/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.4273 - val_loss: 14.0526\n",
      "Epoch 10/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.3882 - val_loss: 14.0418\n",
      "Epoch 11/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.3096 - val_loss: 14.1907\n",
      "Epoch 12/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.3188 - val_loss: 14.1228\n",
      "Epoch 13/30\n",
      "183561/183561 [==============================] - 3s 17us/step - loss: 13.2492 - val_loss: 14.0459\n",
      "Epoch 00013: early stopping\n",
      "Fold no 9/11\n",
      "Train on 183561 samples, validate on 18356 samples\n",
      "Epoch 1/30\n",
      "183561/183561 [==============================] - 4s 20us/step - loss: 14.3833 - val_loss: 14.9519\n",
      "Epoch 2/30\n",
      "183561/183561 [==============================] - 3s 17us/step - loss: 13.8262 - val_loss: 14.5819\n",
      "Epoch 3/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.6842 - val_loss: 14.4764\n",
      "Epoch 4/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.5894 - val_loss: 14.4600\n",
      "Epoch 5/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.5490 - val_loss: 14.5354\n",
      "Epoch 6/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.4881 - val_loss: 14.3863\n",
      "Epoch 7/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.4712 - val_loss: 14.3754\n",
      "Epoch 8/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.4539 - val_loss: 14.3882\n",
      "Epoch 9/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.3587 - val_loss: 14.3609\n",
      "Epoch 10/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.3573 - val_loss: 14.4026\n",
      "Epoch 11/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.3386 - val_loss: 14.3876\n",
      "Epoch 12/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.2859 - val_loss: 14.3712\n",
      "Epoch 13/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.2725 - val_loss: 14.3846\n",
      "Epoch 14/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.2113 - val_loss: 14.2953\n",
      "Epoch 15/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.1743 - val_loss: 14.3859\n",
      "Epoch 16/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.1209 - val_loss: 14.3535\n",
      "Epoch 17/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.0797 - val_loss: 14.4029\n",
      "Epoch 18/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.0415 - val_loss: 14.5070\n",
      "Epoch 19/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.0394 - val_loss: 14.4551\n",
      "Epoch 00019: early stopping\n",
      "Fold no 10/11\n",
      "Train on 183561 samples, validate on 18356 samples\n",
      "Epoch 1/30\n",
      "183561/183561 [==============================] - 4s 21us/step - loss: 14.7070 - val_loss: 12.2919\n",
      "Epoch 2/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 14.1556 - val_loss: 12.2018\n",
      "Epoch 3/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.9642 - val_loss: 12.1326\n",
      "Epoch 4/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.8367 - val_loss: 12.1469\n",
      "Epoch 5/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.7708 - val_loss: 12.1645\n",
      "Epoch 6/30\n",
      "183561/183561 [==============================] - 3s 19us/step - loss: 13.7642 - val_loss: 12.2412\n",
      "Epoch 7/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.6819 - val_loss: 12.1379\n",
      "Epoch 8/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.6487 - val_loss: 12.1231\n",
      "Epoch 9/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.6331 - val_loss: 12.1392\n",
      "Epoch 10/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.5915 - val_loss: 12.1743\n",
      "Epoch 11/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.5442 - val_loss: 12.1194\n",
      "Epoch 12/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.4955 - val_loss: 12.3069\n",
      "Epoch 13/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.4850 - val_loss: 12.1930\n",
      "Epoch 14/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.4144 - val_loss: 12.3617\n",
      "Epoch 15/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.4190 - val_loss: 12.1645\n",
      "Epoch 16/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.3752 - val_loss: 12.0928\n",
      "Epoch 17/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.3000 - val_loss: 12.1358\n",
      "Epoch 18/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.3039 - val_loss: 12.1286\n",
      "Epoch 19/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.2241 - val_loss: 12.2480\n",
      "Epoch 20/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.2097 - val_loss: 12.4581\n",
      "Epoch 21/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.1367 - val_loss: 12.2008\n",
      "Epoch 00021: early stopping\n",
      "Fold no 11/11\n",
      "Train on 183561 samples, validate on 18356 samples\n",
      "Epoch 1/30\n",
      "183561/183561 [==============================] - 4s 21us/step - loss: 14.5616 - val_loss: 14.3431\n",
      "Epoch 2/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.9517 - val_loss: 14.1384\n",
      "Epoch 3/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.7581 - val_loss: 14.1516\n",
      "Epoch 4/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.6975 - val_loss: 13.8827\n",
      "Epoch 5/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.6226 - val_loss: 13.8966\n",
      "Epoch 6/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.5802 - val_loss: 13.8912\n",
      "Epoch 7/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.5310 - val_loss: 13.8661\n",
      "Epoch 8/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.4458 - val_loss: 13.9040\n",
      "Epoch 9/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.4229 - val_loss: 13.8978\n",
      "Epoch 10/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.3807 - val_loss: 13.9055\n",
      "Epoch 11/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.4224 - val_loss: 13.9045\n",
      "Epoch 12/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.3247 - val_loss: 13.8370\n",
      "Epoch 13/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.2895 - val_loss: 13.9001\n",
      "Epoch 14/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.2932 - val_loss: 13.8600\n",
      "Epoch 15/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.1882 - val_loss: 13.9059\n",
      "Epoch 16/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.2293 - val_loss: 13.9221\n",
      "Epoch 17/30\n",
      "183561/183561 [==============================] - 3s 18us/step - loss: 13.1876 - val_loss: 13.9437\n",
      "Epoch 00017: early stopping\n"
     ]
    }
   ],
   "source": [
    "folds = KFold(n_splits=N_FOLDS, shuffle=True, random_state=2019)\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train.values, target.values)):\n",
    "    print('Fold no %i/%i'%(fold_+1,N_FOLDS))\n",
    "    trn_data = X_train.iloc[trn_idx][features]\n",
    "    trn_label = target.iloc[trn_idx]\n",
    "    val_data = X_train.iloc[val_idx][features]\n",
    "    val_label = target.iloc[val_idx]\n",
    "    model = nn_model(trn_data.shape[1])\n",
    "    hist = model.fit(trn_data,trn_label,\n",
    "                     validation_data = (val_data, val_label),\n",
    "                     epochs=EPOCHS, \n",
    "                     batch_size=512, \n",
    "                     verbose=True, \n",
    "                     callbacks=[early_stop])\n",
    "    oof_train_nn[val_idx,0] = model.predict(val_data)[:,0]\n",
    "    oof_test_nn[:,0] += model.predict(X_test[features])[:,0]/N_FOLDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "3891d99d7e2e5a289d95927dba620fec8c686014",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CV score for neural network: 3.69827\n"
     ]
    }
   ],
   "source": [
    "score_nn = mean_squared_error(oof_train_nn, target)**0.5\n",
    "print('Training CV score for neural network: %.5f' %score_nn)\n",
    "layer1_names.append('neural_net')\n",
    "layer1_score.append(score_nn)\n",
    "\n",
    "oof_train = np.hstack((oof_train, oof_train_nn))\n",
    "oof_test = np.hstack((oof_test, oof_test_nn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b8961f81ec04b90554d5e36d0177cf0645d855a6"
   },
   "source": [
    "#### Layer 1 summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "f442a72a9eb2c91add955488c3c209e2e14697f7",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>CV_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lightgbm1</td>\n",
       "      <td>3.648773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>catboost1</td>\n",
       "      <td>3.648872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>3.679188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LGB</td>\n",
       "      <td>3.646658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGB</td>\n",
       "      <td>3.647998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>neural_net</td>\n",
       "      <td>3.698269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       models  CV_score\n",
       "0   lightgbm1  3.648773\n",
       "1   catboost1  3.648872\n",
       "2     xgboost  3.679188\n",
       "3         LGB  3.646658\n",
       "4         XGB  3.647998\n",
       "5  neural_net  3.698269"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print first layer result\n",
    "layer1 = pd.DataFrame()\n",
    "layer1['models'] = layer1_names\n",
    "layer1['CV_score'] = layer1_score\n",
    "layer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "01896a7b9e3031e39f208d552fee686181b6ffa9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Pair-wise correlation')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "layer1_corr = pd.DataFrame()\n",
    "for i in range(len(layer1_names)):\n",
    "    layer1_corr[layer1_names[i]] = oof_train[:,i]\n",
    "layer1_corr['target'] = target\n",
    "colormap = plt.cm.RdBu\n",
    "plt.figure(figsize=(12,12))\n",
    "sns.heatmap(layer1_corr.astype(float).corr(), linewidths=0.1, vmax=1.0, vmin=-1., square=True, cmap=colormap, linecolor='white', annot=True)\n",
    "plt.title('Pair-wise correlation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3d1025058574c71118ff479af923547a4036a3fc"
   },
   "source": [
    "### Second layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "18dfb0e87854e90ae33f0933af01065062300c23"
   },
   "outputs": [],
   "source": [
    "# Setup the model\n",
    "ridge = Ridge(alpha=0.5)#, fit_intercept=False)\n",
    "lasso = Lasso(alpha=0.5)\n",
    "lars = Lars(fit_intercept=False, positive=True)\n",
    "layer2_models = [lars]#[ridge]# lasso]\n",
    "layer2_names = ['Lars']#['ridge'] #, 'lasso']\n",
    "#params_grid = {'alpha':[0.05,0.1,0.4,1.0]}\n",
    "\n",
    "# Setup to record result\n",
    "train_pred = np.zeros(len(train))\n",
    "test_pred = np.zeros(len(test))\n",
    "\n",
    "layer2 = pd.DataFrame()\n",
    "layer2['models'] = layer2_names\n",
    "layer2_score = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_uuid": "75059c60d4056e1caf4018938e2d7f7512a6314d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training Lars\n",
      "Training score: 3.64381\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lightgbm1</td>\n",
       "      <td>0.068676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>catboost1</td>\n",
       "      <td>0.259549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.092281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LGB</td>\n",
       "      <td>0.329477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGB</td>\n",
       "      <td>0.227785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>neural_net</td>\n",
       "      <td>0.080069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Name  Coefficient\n",
       "0   lightgbm1     0.068676\n",
       "1   catboost1     0.259549\n",
       "2     xgboost     0.092281\n",
       "3         LGB     0.329477\n",
       "4         XGB     0.227785\n",
       "5  neural_net     0.080069"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For regression\n",
    "\n",
    "for i in range(len(layer2_models)):\n",
    "    print('\\n')\n",
    "    name = layer2_names[i]\n",
    "    model = layer2_models[i]\n",
    "    print('Training %s' %name)\n",
    "    #model, score = do_regressor((oof_train, target), model=model, parameters=params_grid)\n",
    "    model.fit(oof_train, target)\n",
    "    score = mean_squared_error(model.predict(oof_train), target)**0.5\n",
    "    train_pred += model.predict(oof_train)/len(layer2_models)\n",
    "    test_pred += model.predict(oof_test)/len(layer2_models)\n",
    "    layer2_score.append(score)\n",
    "    print('Training score: %.5f' % score)\n",
    "\n",
    "#layer2['CV score'] = layer2_score\n",
    "#layer2\n",
    "\n",
    "layer2_coef = pd.DataFrame()\n",
    "layer2_coef['Name'] = layer1_names\n",
    "layer2_coef['Coefficient'] = model.coef_\n",
    "#layer2_coef['Coefficient'] = coef\n",
    "layer2_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_uuid": "e41a01c2e2f256ba00678f0bfa3f93cbfe3d33b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Taking average\\ntrain_pred = np.mean(oof_train, axis=1)\\ntest_pred = np.mean(oof_test, axis=1)\\nprint('Training score: %.5f' %mean_squared_error(train_pred, target)**0.5)\\n\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Taking average\n",
    "train_pred = np.mean(oof_train, axis=1)\n",
    "test_pred = np.mean(oof_test, axis=1)\n",
    "print('Training score: %.5f' %mean_squared_error(train_pred, target)**0.5)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_uuid": "9cfb750ba870534ffbeeed38950fe9c51b6b3e8b"
   },
   "outputs": [],
   "source": [
    "#np.sum(model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_uuid": "29066ed554eb1dc196760fb8e17fc52e200b75c4",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgEAAAFUCAYAAAC9Te+4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xm4ZFV57/Hvj+5GEERAWgUUUKOiGBRtp6sCXhUVEyUSH6c45NGguSHqNdGYK3pbQeOQmHhDHFAUowYcgsRoIoYbEYlKbETwdmwFlKkFaWSQRsb2vX/sfbAozlCnT42nvp/n2c85tVatvd+9d52z3lp7Ve1UFZIkafpsM+oAJEnSaJgESJI0pUwCJEmaUiYBkiRNKZMASZKmlEmAJElTyiRA6rMkpyf56KjjGLUkL09yW5/W9bwkFybZkuSEfqxz3CS5KMlRHY99HWngVo46AKlf2s7hPlX11FHH0inJacBlVfXyUccyiZKsAD4GHNsum0cb0dA8F+hLEiXNxSRA0pySbFtVt4w4jN2BHYF/qaqNW7uSJKuA22pCviGtqq4edQxa/rwcoKmR5G5JPpxkU5KbkqxLckhH/deTHNfVJu0w9Nr28SOT/GuSK5NsTvKdJM+YZ5snAE8BXpak2uXgXrY1x/pemeQHbfw/T3JGkvt01D8qyVeS/KKN7z+TPLaj/mVJ/ivJzUkuS3JMkpUd9acnOT7J0UkuBza25SuTrE3yk3bb65O8aqFj3rZ9avv8m9p4HtlV/6gkX23j3ZTk5CR7t3UvBy5tn3rGzPFr6w5Ncna7L1cm+UCSHTqPfZLTkvxxkouAm4Ed2ro/TrKhjen8JG/uPA6z7MOqJO9rj9nNSS5PclLXc57fxjNzbv41yS5t3dPaY3t1kuva8/+YBY7bHS4HzDxO8pYkV7TrOqFrn7dJ8s72OG5OclKS16VPl2W0DFWVi8uyWIATgNPmqf8ccBHwdOAhwPuBW4B92/oXAtcDO3a0eQqwBdirfXww8DLgocCDgGPadTyoo83pwEfb3+8OnAF8Brh3u2zby7Zmif9RNMPDLwX2Bn4TeCXNJRCA/YAbgBOBNcAD2+08vq1/Vrv+P29jfz5wDXB0V+zXAx9q9/E3O47tecAhwP3attcCr5jneL8c+BXwXeAgYH/gS8DlwF3b5zyUZnj/bcC+7T59DvgRsB2wPfBooIBndxy//dtj8dftuXwmcAnwya7Xwy+ALwCPaNe9ElgLXAz8Trsvh7Ztj55nX14PXNae/73amF7XUf/7wK3AW9p92h94LbBbW/87wPPa474f8FHgauAeHeu4CDhqttdRx+Nr233eF3hG+/htXXFuBl7Snv/Xt9u5bdR/ny7juYw8ABeXfi3MkwQAv9F2JId2lX8X+Fj7+7bAJuCVHfUnAl9eYLvnAm/ueNz9z/s04ISuNoveVtuRXAfsNEf9J9tYtpmj/hvAZ7vKXgvcCGzbEfuPOtfRdpS/ok2WOsrfCnxvnnhf3h7zp3SU7dJ2Uq/sOGcndbW7C/BL4LD28T7tep7Yta//2dXuOW2ce3es+1rumGjdtV33M7ravhS4dp59eT/w70DmqL8EOHYRr9VtaBKwF3eUXcTCScB5Xev5EPCtjscb6UpmgJMwCXCZY/FygKbFQ9ufZ3SVn0Hzzoxqrn2fAPwBQJJ70HS8H5l5cpLV7bDzhiTXJtnctt97McH0sq1Z/BvwY+An7TDvEUl266h/FPB/q+pXc7Tfjzvv/9dp3nE/oKPs7K51rAECrGuHmDe3+/2/aN5tLuRbM79U1TXAD/j1+Xg08Dtd6/15G9N8655rX9KxboAfVFXnRML9aEYX/rFrmx8G7p5k9Rzb+zjNSMIFST6U5PAk2wIkuSdwX+CrcwWb5H5JPpnkgiS/oBmhuDuLfN0A3+t6vBG4V7uNnYA9gG93PedbSHNwYqCmXWjeZc74MPAnSfYH/jvNUOqXOupPoBkOfiPwE5p30SfRvLNfrIW2dQdVtTnJGuAJwFOBVwPvSfKUqjp75mkLbLO7PrOU39D1nJk3C/+N5l30fOvrRTp+34bmXf27ZnnezxdYz1zb7mVfnkcz4tFt1sl4VfW9JPcDngY8mWZk4Ogkj+shHmjO61XAH9HMcbgFOJPFv266J2kWv96n2c6lNC9HAjQt1rc/D+wqf1JHHVV1Ac2w7x/QXG//eFV1Tqo6EPhAVX2xqr5Pc337/gts+xZgRXdhD9u6k6raUlVnVNVbad75Xw68qK0+G3hqkrn+rtfTXJvvdCBNIvPjeTY7k2DsVVUXdC0Xzhdv6/aOMsnONNezf9AWraO5fn7hLOu+Zp51zrYvB9F0gP+1QLubgPvPsr0LqmrLXA2ranNVfaGqXkMzOvIQ4KCqupJmvsDTZ2vXjvI8FHhXVZ1aVf/VxnDPeeJctKq6Dvgp8PiuqsfN8nQJcCRAy8+OSR7RVXZTVW1I8jngA+2s9ouBPwQexq870RkfBj4FrAJ+u6vuh8CLk5xJ07G/nVk6+C4/AZ6c5AE01/Svq6pbe9jWHSR5Dk3CcQbNfIJH0QxDz3R67wHOAj6d5K9orjk/kuY7Cr4F/AXwz0neBJxMM1luLfBXNc/HAKvqgiQfAz6S5I00w8s7tNtfXVXvnifsohmteH0bzzto3p3/Q1v/TuA/gU8leX+7X/sAhwHvr6q5kpP3At9N8j7guLbN3wKfrqpL5tmXzUneCbwzCTSXWFbSDPUfUFV/Nlu7JG+g6WC/RzMa8kKaSZYzowlvAz6Y5GfA52neYD2ZZpTo6na//iDJhcA9aM7VjXPFuQR/BbwtyQaa4/osmsmcjg5odqOelODi0q+FZqi+Zlk2tPU70XS6m2g+LrYOOGSW9awCrgROnaXuN4Fv0vwDvwj4H3RN/OPOE7pmOu7NbTwH97KtWbZ9IM3IwSaad5LnA2+iY7Ia8Jg2nhtoZvmfBTymo/5lNO/Cb6G5nvwOYOVcsXeUr6C5BLKhbXsVzTX4580T78tpZvAf0m7zZuA7wJpZjuk/0SQJNwIX0HTsu7b1+9A1MbAtP5RmlOLm9ph8ENih6/Uw10TRV9B06De12z0L+MN59uVV7bZ+0Z7H7wDP6XrOi2kmZt5Mcynjy8DObd1Bbd1NNInk4e1+ru1ofxELTwz8aNc2jwIu6ni8DU2yd1Ub50k0czeuH/Xfp8t4LqkyQZQ6JdmVpoP8var6x+WyLU2ndhTn4VX1qFHHovHj5QCpleYb5e5F81nvnwKnLIdtaXok2YPmUyZfo7lc8ds0H388cpRxaXyZBEi/9gSaf54/AV5a80wSm7BtaXpsofnkw9E0H7O8gOYyx3wfPdUU83KAJElTyo8ISpI0pUwCJEmaUst+TsBuu+1W++yzz6jDkCRpaM4+++yrqmqur8G+3bJPAvbZZx/WrVs36jAkSRqaJBf38jwvB0iSNKVMAiRJmlImAZIkTSmTAEmSppRJgCRJU8okQJKkKWUSIEnSlFr23xMgSdI4OuqU73PiWZeypYoVCS987H055rDfHGoMJgGSJA3ZUad8n099+5LbH2+puv3xMBMBLwdIkjRkJ5516aLKB8UkQJKkIdtStajyQTEJkCRpSpkESJI0pUwCJEmaUiYBkiRNKZMASZKmlEmAJElTyiRAkqQpZRIgSdKUMgmQJGlKmQRIkjSlTAIkSZpSJgGSJE0pkwBJkqaUSYAkSUO0z5u+POoQbmcSIEnSlDIJkCRpSMZpFABMAiRJGopxSwAAVo46AEmSlqtx7Pg7mQRIktRHS+n4L3rXs/oYycJMAiRJ2grj/i6/FyYBkiTNY1id/bBHAcAkQJKkkb+rH0UCACYBkqRlbtQd/EJGlQCASYAkaYKNewe/kFEmAGASIEkaQ5Peuc9n1B1/J5MASdJQLOeOfSHj1PF3MgmQJC3KNHfmCxnXzn4uJgGSNGXsxJdu0jr7uZgESNIYs8MeneXS0c9n4pKAJLsCxwOHAFcBf15V/zDaqCRNIzvoyTUNHXwvJi4JAP4OuAW4F/AI4MtJzq2q9aMNS9Io2SFrhh187yYqCUiyA3A48LCq2gycmeSLwEuAN400OEm3s0PWINi5999EJQHAg4AtVfWjjrJzgYM6n5TkCOAIgL322mt40Ulj6mnvO53zr7xh1GFId2LHPlqTlgTsCFzXVXYdcLfOgqo6DjgOYM2aNTWc0KSt5ztnTTo788k0aUnAZmCnrrKdgOtHEIumlB22liM78ek0aUnAj4CVSR5YVee3ZQ8HnBSoBdl5a7mww1a/TFQSUFU3JDkZeHuSV9J8OuA5wH8bbWQaFjtyjTs7aE2SiUoCWv8D+BhwJfBz4A/9eODkslPXINkhS/ObuCSgqq4GDht1HJqbM9E1GztkafxMXBKg0TrqlO/zqW9fMuow1Ad2ypJMAnQnDtGPBztpSYNmEjDF7Oz7xw5b0iQyCZgCdvZzs/OWNM1MApahaev07cglaeuYBCwDy63Tt1OXpOEwCZhAk9jp27FL0vgxCZgQ49zx28FL0mQyCRhz49L529FL0vJjEjCGRtnx29lL0vQwCRgjw+z87ewlSSYBY2AYnb+dviSpm0nACA2q899uRdjwjkMHsm5J0vJhEjAi/U4AfKcvSVosk4AR6FcCYMcvSVoKk4AhsvOXJI0Tk4AhWWoCYMcvSeo3k4AhWEoCYOcvSRoUk4AB29oEwM5fkjRoJgFjxs5fkjQs24w6gOVssaMAJgCSpGEyCRgQEwBJ0rjzcsAALCYBsPOXJI2KIwF9ZgIgSZoUJgEj8sB77jDqECRJU84koI8WMwrwb68/eHCBSJLUA5OAEfAygCRpHJgE9EmvowAmAJKkcWESMEQmAJKkcWIS0Af9ujugJEnDZBIwJI4CSJLGjUnAEjkKIEmaVCYBQ+AogCRpHJkESJI0pUwCBsxRAEnSuDIJWALnA0iSJplJwAA5CiBJGmcmAZIkTSmTAEmSptTEJAFJTk9yU5LN7fLDUcbjfABJ0qSbmCSgdWRV7dguDx51MPNxPoAkadxNWhIgSZL6ZNKSgL9IclWS/0hy8KiDkSRpkk1SEvBnwP2BPYHjgH9O8oDZnpjkiCTrkqzbtGnTMGOUJGlijEUS0E76qzmWMwGq6qyqur6qbq6qTwD/ARw62/qq6riqWlNVa1avXj3MXQGcDyBJmgwre31ikocAvwvcu6r+KMm+wLZVdd5Sg6iqg7emGZClbntr+MkASdJy0NNIQJLnAV+nGYp/SVu8I/C+AcXVvf2dkzw9yXZJViZ5MXAgcOowti9J0nLU60jA24FDqup7SZ7flp0LPHwwYd3JKuAYYF9gC7ABOKyqRvpdAZIkTbJek4B70nT60AzDz/ys2Z/eX1W1CXj0MLYlSdK06HVi4Nn8+jLAjBcA/9nfcCRJ0rD0OhLwGuCrSV4B7JDkVOBBwCEDi2xC+ckASdKk6CkJqKoN7acBfgv4EnAp8KWq2jzI4CRJ0uAsmAQkWQH8CHhoVX128CFJkqRhWHBOQFVtoZmRv/3gw5EkScPS65yAvwE+k+SdwGV0fCqgqn48iMDGlV8UJElaLnpNAo5tfz6tq7yAFf0LR5IkDUuvEwPH4h4DkiSpf3q+dwBAkr1ovjr4sqq6dDAhSZKkYej13gG7J/k6cAFwMnBhkjOS7DHQ6CbMditGcj8jSZK2Sq/D/B+k+drgXapqd2AX4BzgQ4MKbBJteMesdzaWJGks9Xo54InA7lV1K0BV3ZDkjcDGgUUmSZIGqteRgGuAh3aVPRi4tr/hSJKkYel1JOA9wGlJjgcuBvYGfh94y6ACkyRJg9XrRwQ/kuRC4EXA/sBPgRdW1b8PMjhJkjQ4PX9EsO3w7fQlSVomev2I4MlJntRV9qQknx9MWJIkadB6nRh4EPDNrrJvAU/ubzjj7WnvO33UIUiS1De9JgE3ATt0le0I3NrfcMbb+VfeMOoQJEnqm16TgFOBDyfZCaD9eSzwlUEFJkmSBqvXJOBPgJ2Aq5NcCVwN3B143aACkyRJg9XrRwSvAZ6V5N7AfYFLq+qKgUYmSZIGalG3CG47/p2BFyZ5/GBCmkwXvetZow5BkqRFmTcJSHJikld2PP4z4Es0Xxp0WpKXDDg+SZI0IAuNBDwB+CJAkm2APwVeVFWPBn63fSxJkibQQknAzlV1Zfv7AcB2wCnt46/Q3ENAkiRNoIWSgKuS7NP+/mTgW1W1pX28A7BltkaSJGn8LfTpgI8CX05yKvBS4I876g4EfjCowCRJ0mDNmwRU1TuTbATWAK+tqhM7qlcDfzXI4CRJ0uAs+D0BVfUJ4BNzlEuSpAm1qO8JkCRJy4dJgCRJU8okQJKkKdVTEpBk/0EHIkmShqvXkYD/m+TcJH+aZPeBRiRJkoai1yRgd+CtwGOB85N8NcnvJbnr4EKTJEmD1FMSUFW3VdU/VdXzgD2BzwJvBH6W5O+TPGGQQUqSpP5b1MTAJDsChwEvAO4DnAScD3w6yd/1PzxJkjQoC35ZEECSZwEvAZ4J/AfN1wmfUlU3tfV/B1wC/NGA4pQkSX3WUxIAvIvmWwP/Z1Vd3l1ZVVcneV1fIxszp5yzcdQhSJLUV71eDji6qv6yOwFI8rszv1fVR5cSSJIjk6xLcnOSE2apf0qSDUl+meRrSYZ6G+PXfeZ7w9ycJEkD12sSMFcHf1y/AgF+ChwDfKy7IsluwMnAW4BdgXXAZ/q4bUmSps68lwOS3L/9dZsk9wPSUX1/4KZ+BVJVJ7fbXEMz6bDTc4H1VfW59jlrgauS7FtVG/oVgyRJ02ShOQEXAEXT+V/YVXcFsHYAMc1mP+DcmQdVdUOSC9tykwBJkrbCvElAVW0DkOTrVXXQcEKa1Y7Apq6y64C7zfbkJEcARwDstddeg40MuOhdzxr4NiRJ6rdevyxoSQlAktOT1BzLmT2sYjOwU1fZTsD1c8R7XFWtqao1q1evXkrokiQtW3OOBCT5Bs2lgHlV1YE9POfgxYV1J+uBl808SLID8IC2XJIkbYX5Lgcs6SN/i5VkJU08K4AVSbYDbquq24AvAO9NcjjwZZr7GJznpEBJkrbenElAVX1imIEARwH/u+Px7wFvA9ZW1aY2ATgW+BRwFs1XF0uSpK3U6zcGkuRewGOA3ej4qGBV3elz/VujqtYyz6cNquo0YN9+bEuSJPV+74DDaN6Bn0/zsbz1wMOAM5nly30kSdL46/UbA48Bfr+qDgBuaH8eAZw9sMgkSdJA9ZoE7DXzbX0dPgG8tM/xSJKkIek1CbiynRMAcFGSx9N8RG/FYMKSJEmD1msS8BHgie3vfw18jeZrfD8wiKAkSdLg9TQxsKre3fH73yc5Hdihqn4wqMAkSdJg9TQSkOQ17e18AaiqS0wAJEmabL1eDngqzVyALyV5fpK7DDIoSZI0eL3eQOjZwN7AvwKvA65I8tEkC943QJIkjadeRwKoqp9X1d9V1eOBg4BHA19LclGSNyfZcWBRSpKkvus5CQBI8pQkHwdOB35G8z0BLwEOoBklkCRJE6LXrw3+S5ob9lwH/D1wVFVt7Kj/NnDNQCKUJEkD0esNhLYDfqeqvjNbZVXdmmRN/8KSJEmD1uv3BBwJkGQvYE9gY1Vd0vWcDf0PT5IkDUqv3xNw7yRfBy4ATgYuSHJGkj0GGp0kSRqYXicGfojma4J3qardgV2Ac9pySZI0gXqdE/BEYPequhWgqm5I8kZg4/zNJEnSuOp1JOAa4KFdZQ8Gru1vOJIkaVh6HQl4D3BakuOBi2m+PfD3gbcMKjBJkjRYvX464CNJLgReBOwP/BR4YVX9+yCDkyRJg9PrSABth397p59kRZK3V9VbBxKZJEkaqEV9bXCXlcCb+xWIJEkarqUkAQDpSxSSJGnolpoEVF+ikCRJQzfvnIAk/32e6m37HIskSRqihSYGHr9A/SUL1EuSpDE1bxJQVfcbViCSJGm4ljonQJIkTSiTAEmSppRJgCRJU8okQJKkKWUSIEnSlDIJkCRpSpkESJI0pUwCJEmaUiYBkiRNKZMASZKmlEmAJElTyiRAkqQpNTZJQJIjk6xLcnOSE7rq9klSSTZ3LG8ZUaiSJC0LC91KeJh+ChwDPB3Yfo7n7FxVtw0vJEmSlq+xSQKq6mSAJGuA+4w4HEmSlr2xuRzQo4uTXJbk40l2G3UwkiRNsklJAq4CHg3sDTwKuBvw6bmenOSIdn7Buk2bNg0pREmSJstQkoAkp7cT+2ZbzlyofVVtrqp1VXVbVf0MOBI4JMlOczz/uKpaU1VrVq9e3e/dkSRpWRjKnICqOrjfq2x/ps/rlSRpaozNxMAkK2niWQGsSLIdcFtV3ZbkscC1wPnALsD/AU6vqutGFrAkSRNunOYEHAXcCLwJ+L3296PauvsDXwGuB/4fcDPwwhHEKEnSsjE2IwFVtRZYO0fdicCJw4xHkqTlbpxGAiRJ0hCZBEiSNKVMAiRJmlImAZIkTSmTgB6tmuNIzVUuSdK4swvr0Q53WbWockmSxp1JQI+uu/HWRZVLkjTuTAJ6tMfO2y+qXJKkcWcS0KN97jF7Zz9XuSRJ484koEff+vHViyqXJGncmQT06Fe1uHJJksadSYAkSVPKJKBHfk+AJGm5sQvr0aoVsx+qucolSRp39mA9+uWtv1pUuSRJ484kQJKkKWUS0KOdt5/964HnKpckadyZBPRo7bP3Y9U2uUPZqm3C2mfvN6KIJElampWjDmBSHHbAngC899Qf8tNrb2SPnbfnDU9/8O3lkiRNGpOARTjsgD3t9CVJy4aXAyRJmlImAZIkTSkvByzCKedsdE6AJGnZMAno0SnnbOQNnz+XW7c0dwzaeO2NvOHz5wKYCEiSJpKXA3r0tn9ef3sCMOPWLcXb/nn9iCKSJGlpTAJ6dM0vb11UuSRJ484kQJKkKWUS0CO/NliStNyYBPTotx6++6LKJUkadyYBPfryeZcvqlySpHFnEtAjJwZKkpYbkwBJkqaUSYAkSVPKJKBHfjpAkrTcmAT0aO2z92PVNrlD2aptwtpn7zeiiCRJWhrvHdCjmfsDeAMhSdJyYRKwCIcdsKedviRp2fBygCRJU8okQJKkKWUSIEnSlBqLJCDJXZIcn+TiJNcnOSfJM7ue85QkG5L8MsnXkuw9qnglSVoOxiIJoJmgeClwEHB34C3AZ5PsA5BkN+DktnxXYB3wmVEEKknScjEWnw6oqhuAtR1FX0ryE+BRwEXAc4H1VfU5gCRrgauS7FtVG4YbrSRJy8NYJAHdktwLeBCwvi3aDzh3pr6qbkhyYVs+tCTglHM2+j0BkqRlY+ySgCSrgE8Dn+h4l78jsKnrqdcBd5tjHUcARwDstddefYnrlHM28ucnf58bb90CwMZrb+TPT/4+gImAJGkiDWVOQJLTk9Qcy5kdz9sG+CRwC3Bkxyo2Azt1rXYn4PrZtldVx1XVmqpas3r16r7sw3tP/eHtCcCMG2/dwntP/WFf1i9J0rANZSSgqg5e6DlJAhwP3As4tKpu7aheD7ys47k7AA/g15cLBu6n1964qHJJksbduHw6AOCDwEOA366q7p71C8DDkhyeZDvgrcB5w5wUuMfO2y+qXJKkcTcWSUD7mf9XAY8ArkiyuV1eDFBVm4DDgXcA1wCPBV4wzBjf8PQHs/2qFXco237VCt7w9AcPMwxJkvpmLCYGVtXFQBZ4zmnAvsOJ6M68i6AkabkZiyRgUngXQUnScjIWlwMkSdLwmQRIkjSlTAIkSZpSJgGSJE0pkwBJkqaUnw5YBG8gJElaTkwCeuQNhCRJy42XA3rkDYQkScuNSUCPvIGQJGm5MQnokTcQkiQtNyYBPfIGQpKk5caJgT3yBkKSpOXGJGARvIGQJGk58XKAJElTyiRAkqQpZRIgSdKUMgmQJGlKmQRIkjSlTAIkSZpSJgGSJE0pkwBJkqZUqmrUMQxUkk3AxX1e7W7AVX1e56TxGDQ8Dg2Pg8dghsehMerjsHdVrV7oScs+CRiEJOuqas2o4xglj0HD49DwOHgMZngcGpNyHLwcIEnSlDIJkCRpSpkEbJ3jRh3AGPAYNDwODY+Dx2CGx6ExEcfBOQGSJE0pRwIkSZpSJgGSJE0pk4BFSLJrki8kuSHJxUleNOqYFivJXZIc38Z/fZJzkjyzo/4pSTYk+WWSryXZu6vtx5L8IskVSV7fte6tbjtKSR6Y5KYkn+ooe1F7jG5IckqSXTvq5n0dLKXtqCR5QZIftHFdmORJbflUvB6S7JPkX5Jc08ZzbJKVbd0jkpzd7sfZSR7R0S5J3p3k5+3yniTpqN/qtkPa7yOTrEtyc5ITuupGcu7nazsIcx2DJI9L8m9Jrk6yKcnnkuzeUT+wcz9f276rKpceF+BE4DPAjsATgeuA/UYd1yL3YQdgLbAPTRL4W8D17ePd2n16HrAd8F7g2x1t/wL4BrAL8BDgCuAZbd1Wtx31Any1je1T7eP92mNyYHuu/wE4qZfXwVLajnD/n0bzhVqPa18Te7bL1LwegH8BTmhjvTfwfeA1wLbtsfmfwF3asouBbdt2rwJ+CNynPWb/Bby6rdvqtkPc7+cChwEfBE7oKB/JuV+o7ZCPwTPbOHYC7gp8DPhKR/1Azv1Cbfu+/6P6o5u0habzvAV4UEfZJ4F3jTq2PuzbecDhwBHAN7v2+UZg3/bxRuCQjvqjaTu4pbQd8b6/APgsTWI0kwS8E/iHjuc8oD33d1vodbCUtiM8Bt8EXjFL+dS8HoAfAId2PH4v8GHgkDbWdNRdwq87rW8CR3TUvYK201pK2xHs/zHcsQMcyblfqO0wj8Es9Y8Eru94PJBzv1Dbfi9eDujdg4AtVfWjjrJzad75Tawk96LZt/U0+3LuTF1V3QBcCOyXZBdgj8567rj/S2k7Ekl2At4O/ElXVfe+XEjbebPw62ApbYcuyQpgDbA6yQVJLmuHwrdnul4P7wdekOSuSfakeRf4lTam86r9T9w6jzn2kzsfg61tO2qjOvdztu3LXi3NgTT/J2cM6twv1LavTAJ6tyPNMFWn62je4U2kJKuATwOfqKoNzL+PO3Y87q5jiW1H5Wjg+Kq6tKt8oX2Z73WwlLajcC+D5bK6AAAE70lEQVRgFfC7wJOARwAHAEcxXa+Hr9P8k/0FcBmwDjiFxZ/v64Ad2+u7S2k7aqM69+P4N0KS/YG3Am/oKB7UuR/qMTAJ6N1mmmtDnXaiuf47cZJsQzMUfQtwZFs83z5u7njcXbfUtkPXTrR5KvDXs1QvtC/zvQ6W0nYUbmx//m1VXV5VVwHvAw5lSl4P7d/CqcDJNMPPu9Fcr343iz/fOwGb23dxS2k7aqM692P3N5LkN4B/BV5bVd/oqBrUuR/qMTAJ6N2PgJVJHthR9nDuODw0Edps83iad4GHV9WtbdV6mn2aed4ONNe011fVNcDlnfXccf+X0nYUDqaZDHlJkiuAPwUOT/Jd7rwv96eZoPMjFn4dLKXt0LXn5jJgto5nWl4PuwL3BY6tqpur6ufAx2kSofXA/l3vzvdnjv3kzsdga9uO2qjO/Zxt+7JXi9R+MuE04Oiq+mRX9aDO/UJt+2vQky2W0wKcRDO7ewfgCYzBzO6t3I8PAd8GduwqX93u0+E0M3PfzR1n9b6LZth0F2Bfmj/mZyy17YiOwV1pZoHPLH8JfL7dj5lh4Se15/pT3HGG/5yvg6W0HeGxeDvwHeCe7fn5Bs2lkml6PfwYeBOwEtgZ+ALNpbKZmdqvpUnmjuSOs7xfTTOpcE+aa93rufMs70W3HeJ+r2zPz1/QjAxu15aN5Nwv1HbIx2BPmvkIb5ij3UDO/UJt+77/o/qjm8SF5h3DKcANNLM1XzTqmLZiH/amedd3E82w08zy4rb+qcAGmmHi04F9OtreheZjMr8Afga8vmvdW9121Asdnw5oH7+oPcc3AP8E7Nrr62ApbUe076uADwDX0nxc6/8A203T64FmLsTpwDU094D/HHDPtu4A4Ox2P74LHNDRLsB7gKvb5T3ccVb3Vrcd4uu+upa1ozz387Ud5jEA/nf7e+f/yc3DOPfzte334r0DJEmaUs4JkCRpSpkESJI0pUwCJEmaUiYBkiRNKZMASZKmlEmAJElTyiRA0pySrE9y8Fa0OyHJMQMISVIfrRx1AJLGV1WNw93bJA2IIwGSJE0pkwBJc0pyUZKnJlmb5LNJ/j7J9e1lgjUdzzsgyXfbus/QfP9653p+K8n3klyb5JvtrVlJ8oAkVyd5ZPt4jyRXbc0lCEmLZxIgqVfPprkB0s7AF4FjAZJsS3M/hE/S3BvhczQ3gKGtfyTNd8W/CrgH8GHgi0nuUlUXAn8GfDrJXWnu3ndCVZ0+pH2SpppJgKRenVlV/1JVW2g6/JlboT6O5iZEf1NVt1bV52nuSjjjD4APV9VZVbWlqj4B3Ny2o6o+ApwPnAXsDrx5OLsjySRAUq+u6Pj9l8B2SVbS3Ap1Y93xbmQXd/y+N/An7aWAa5NcC9y3bTfjI8DDgL+tqpsHE76kbiYBkpbqcmDPJOko26vj90uBd1TVzh3LXavqRIAkOwJ/AxwPrE2y69Ail6acSYCkpfoWcBvwmiQrkzwXeExH/UeAVyd5bBo7JHlWkru19e8Hzq6qVwJfBj401OilKWYSIGlJquoW4LnAy4FrgOcDJ3fUr6OZF3BsW39B+1ySPAd4BvDq9umvBx6Z5MXDiV6abrnjZTxJkjQtHAmQJGlKmQRIkjSlTAIkSZpSJgGSJE0pkwBJkqaUSYAkSVPKJECSpCllEiBJ0pQyCZAkaUr9f+9aPlTTSob5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.scatter(range(len(test_pred)), np.sort(test_pred))\n",
    "plt.xlabel('index', fontsize=12)\n",
    "plt.ylabel('Loyalty Score', fontsize=12)\n",
    "plt.title('Loyalty score before scaling')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_uuid": "037b8320701f902bc2ee267984139a77fb6f9ade"
   },
   "outputs": [],
   "source": [
    "# Refit to the target\n",
    "train_scaler = StandardScaler()\n",
    "#train_scaler.fit(target.values.reshape(-1,1))\n",
    "#test_pred = train_scaler.inverse_transform(test_pred.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "61f5c9202172b3e6b90fd9bc2c1982219e6ecd64"
   },
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_uuid": "e6cf79c20304e868c09dfd7d6610fc3eb32853ab"
   },
   "outputs": [],
   "source": [
    "#sub_df = pd.DataFrame({\"card_id\":test[\"card_id\"].values})\n",
    "sample_submission = pd.read_csv('../input/sample_submission.csv')\n",
    "sample_submission[\"target\"] = test_pred\n",
    "sample_submission.to_csv(\"model-stacking-ensemble-low_features-StratifiedKFold11.csv \", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_uuid": "70e785327f87a8416fcf8afa29ae1f1c2c14914d"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sub_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-ed78c58e2591>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msub_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msub_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'target'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'index'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loyalty Score'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loyalty score after scaling'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sub_df' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.scatter(range(sub_df.shape[0]), np.sort(sub_df['target'].values))\n",
    "plt.xlabel('index', fontsize=12)\n",
    "plt.ylabel('Loyalty Score', fontsize=12)\n",
    "plt.title('Loyalty score after scaling')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
