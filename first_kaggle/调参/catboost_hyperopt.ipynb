{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "\n",
    "import sklearn\n",
    "import numpy\n",
    "import catboost\n",
    "import hyperopt\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "import colorama\n",
    "import numpy as np\n",
    "import mnist_loader\n",
    "import mnist_vae\n",
    "\n",
    "\n",
    "# кол-во случайных наборов гиперпараметров\n",
    "N_HYPEROPT_PROBES = 500\n",
    "\n",
    "# алгоритм сэмплирования гиперпараметров\n",
    "HYPEROPT_ALGO = tpe.suggest  #  tpe.suggest OR hyperopt.rand.suggest\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "colorama.init()\n",
    "\n",
    "\n",
    "#(X_train, y_train, X_val, y_val, X_test, y_test ) =  mnist_loader.load_mnist()\n",
    "(X_train, y_train, X_val, y_val, X_test, y_test ) =  mnist_vae.load_mnist()\n",
    "\n",
    "D_train = catboost.Pool(X_train, y_train)\n",
    "D_val = catboost.Pool(X_val, y_val)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "def get_catboost_params(space):\n",
    "    params = dict()\n",
    "    params['learning_rate'] = space['learning_rate']\n",
    "    params['depth'] = int(space['depth'])\n",
    "    params['l2_leaf_reg'] = space['l2_leaf_reg']\n",
    "    params['rsm'] = space['rsm']\n",
    "    return params\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "obj_call_count = 0\n",
    "cur_best_loss = np.inf\n",
    "log_writer = open( 'catboost-hyperopt-log.txt', 'w' )\n",
    "\n",
    "\n",
    "def objective(space):\n",
    "    global obj_call_count, cur_best_loss\n",
    "\n",
    "    obj_call_count += 1\n",
    "\n",
    "    print('\\nCatBoost objective call #{} cur_best_loss={:7.5f}'.format(obj_call_count,cur_best_loss) )\n",
    "\n",
    "    params = get_catboost_params(space)\n",
    "\n",
    "    sorted_params = sorted(space.iteritems(), key=lambda z: z[0])\n",
    "    params_str = str.join(' ', ['{}={}'.format(k, v) for k, v in sorted_params])\n",
    "    print('Params: {}'.format(params_str) )\n",
    "\n",
    "    model = catboost.CatBoostClassifier(iterations=5000,\n",
    "                                        learning_rate=params['learning_rate'],\n",
    "                                        depth=int(params['depth']),\n",
    "                                        loss_function='MultiClass',\n",
    "                                        use_best_model=True,\n",
    "                                        eval_metric='MultiClass',\n",
    "                                        l2_leaf_reg=params['l2_leaf_reg'],\n",
    "                                        auto_stop_pval=1e-3,\n",
    "                                        random_seed=123456,\n",
    "                                        verbose=False\n",
    "                                        )\n",
    "    model.fit(D_train, eval_set=D_val, verbose=True)\n",
    "    nb_trees = model.get_tree_count()\n",
    "\n",
    "    print('nb_trees={}'.format(nb_trees))\n",
    "\n",
    "    y_pred = model.predict_proba(X_test)\n",
    "\n",
    "    test_loss = sklearn.metrics.log_loss(y_test, y_pred, labels=list(range(10)))\n",
    "    acc = sklearn.metrics.accuracy_score(y_test, numpy.argmax(y_pred, axis=1))\n",
    "\n",
    "    log_writer.write('loss={:<7.5f} acc={} Params:{} nb_trees={}\\n'.format(test_loss, acc, params_str, nb_trees ))\n",
    "    log_writer.flush()\n",
    "\n",
    "    if test_loss<cur_best_loss:\n",
    "        cur_best_loss = test_loss\n",
    "        print(colorama.Fore.GREEN + 'NEW BEST LOSS={}'.format(cur_best_loss) + colorama.Fore.RESET)\n",
    "\n",
    "\n",
    "    return{'loss':test_loss, 'status': STATUS_OK }\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "\n",
    "space ={\n",
    "        'depth': hp.quniform(\"depth\", 4, 7, 1),\n",
    "        'rsm': hp.uniform ('rsm', 0.75, 1.0),\n",
    "        'learning_rate': hp.loguniform('learning_rate', -3.0, -0.7),\n",
    "        'l2_leaf_reg': hp.uniform('l2_leaf_reg', 1, 10),\n",
    "       }\n",
    "\n",
    "\n",
    "trials = Trials()\n",
    "best = hyperopt.fmin(fn=objective,\n",
    "                     space=space,\n",
    "                     algo=HYPEROPT_ALGO,\n",
    "                     max_evals=N_HYPEROPT_PROBES,\n",
    "                     trials=trials,\n",
    "                     verbose=1)\n",
    "\n",
    "print('-'*50)\n",
    "print('The best params:')\n",
    "print( best )\n",
    "print('\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
